{
    "metadata": {
        "language_info": {
            "file_extension": ".py", 
            "nbconvert_exporter": "python", 
            "mimetype": "text/x-python", 
            "version": "3.5.2", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 3
            }, 
            "pygments_lexer": "ipython3", 
            "name": "python"
        }, 
        "kernelspec": {
            "name": "python3-spark20", 
            "language": "python", 
            "display_name": "Python 3.5 (Experimental) with Spark 2.0"
        }
    }, 
    "nbformat": 4, 
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Analyze Facebook Data with IBM Watson services\n\nIn this Python 3.5 notebook, you'll learn how to enrich and analyze a combined data set of unstructured and structured information with IBM Watson services. You'll analyze a standard Facebook Analytics export that includes photos and text from posts, articles, and thumbnails, plus standard performance metrics, such as likes, shares, and impressions. You'll visualize the results with PixieDust.\n\nThis notebook runs on Python 3.5 with Spark 2.0.\n\nThis notebook has three main parts:\n\n**Part I**: Use the IBM Watson Natural Language Understanding, Tone Analyzer, and Visual Recognition services to enrich the Facebook posts, thumbnails, and articles with image classification and these semantic features: emotion tones, social tones, language tones, entities, keywords, and document sentiment. The results of Part I will be features and metrics that you'll  visualize in Part III. \n\n**Part II**: Create pandas DataFrames for the three main features: tone, keywords, and entities. You'll use these DataFrames to find insights with the visualizations in Part III.\n\n**Part III**: Visualize the post consumption by tone, entity, and keyword with PixieDust.\n\n## Table of Contents \n### [Part I - Enrich the data](#part1)<br>\n1. [Setup](#setup)<br>\n   1.1 [Install the necessary packages](#setup1)<br>\n   1.2 [Import packages and libraries](#setup2)<br>\n   1.3 [Add your service credentials from Bluemix for the Watson services](#setup3)<br>\n2. [Load the data and set variables](#load)<br>\n    2.1 [Load the data](#load1)<br>\n    2.2 [Set variables](#load2)<br>\n3. [Prepare the data](#prepare)<br>\n   3.1 [Cleanse the data](#prepare1)<br>\n   3.2 [Extract thumbnails and extended links](#prepare2)<br>\n4. [Enrich the data](#enrich)<br>\n   4.1 [Enrich the post text with NLU](#enrich1)<br>\n   4.2 [Enrich the thumbnail text with NLU](#enrich2)<br>\n   4.3 [Enrich the article text with NLU](#enrich3)<br>\n   4.4 [Run Tone Analyzer on the post text](#tonepost)<br>\n   4.5 [Run Tone Analyzer on the article text](#tonearticle)<br>\n   4.6 [Classify images with Visual Recognition](#imageclass)<br>\n5. [Save the enriched DataFrame to object storage](#write)<br>\n    \n### [Part II - Prepare the data](#part2)<br>\n1. [Sort data by feature](#p2prepare)<br>\n   1.1 [Create a list of metrics](#visualizations)<br>\n   1.2 [Create a consolidated tone DataFrame](#tone)<br>\n   1.3 [Create a consolidated keyword DataFrame](#keyword)<br>\n   1.4 [Create a consolidated entity DataFrame](#entity)<br>\n  \n### [Part III - Analyze the data](#part3)<br>\n\n1. [Define variables](#2setup)<br> \n2. [Visualize the data with PixieDust](#viz)<br>\n   2.1 [View post consumption by tone](#viz1)<br>\n   2.2 [View post consumption by entity](#viz2)<br>\n   2.3 [View post consumption by keyword](#viz3)<br>\n\n### [Summary](#summary) ", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown"
        }, 
        {
            "source": "# <a id=\"part1\"></a> Part I: Enrich the data\n\n## <a id='setup'></a> 1. Setup\nTo prepare your environment, you need to install some packages and enter credentials for the two Watson services.\n\n### <a id=\"setup1\"></a>1.1 Install the necessary packages\nYou need the latest versions of these packages:\n - Watson Developer Cloud: a client library for Watson services.\n - <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\" target=\"_blank\" rel=\"noopener noreferrer\">Beautiful Soup</a>: a library to parse data from HTML for enriching the Facebook data.\n - <a href=\"https://ibm-cds-labs.github.io/pixiedust/\" target=\"_blank\" rel=\"noopener noreferrer\">PixieDust</a>: a library to visualize the data. \n\nInstall the Watson Developer Cloud package:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 7, 
            "source": "!pip install --upgrade watson-developer-cloud", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Collecting watson-developer-cloud\n  Using cached watson-developer-cloud-1.0.2.tar.gz\nCollecting requests<3.0,>=2.0 (from watson-developer-cloud)\n  Downloading requests-2.18.4-py2.py3-none-any.whl (88kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 457kB/s eta 0:00:01\n\u001b[?25hCollecting pysolr<4.0,>=3.3 (from watson-developer-cloud)\n  Downloading pysolr-3.7.0.tar.gz (44kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 1.4MB/s eta 0:00:01\n\u001b[?25hCollecting pyOpenSSL>=16.2.0 (from watson-developer-cloud)\n  Using cached pyOpenSSL-17.5.0-py2.py3-none-any.whl\nCollecting python_dateutil>=2.5.3 (from watson-developer-cloud)\n  Using cached python_dateutil-2.6.1-py2.py3-none-any.whl\nCollecting urllib3<1.23,>=1.21.1 (from requests<3.0,>=2.0->watson-developer-cloud)\n  Downloading urllib3-1.22-py2.py3-none-any.whl (132kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133kB 1.7MB/s eta 0:00:01\n\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests<3.0,>=2.0->watson-developer-cloud)\n  Using cached chardet-3.0.4-py2.py3-none-any.whl\nCollecting certifi>=2017.4.17 (from requests<3.0,>=2.0->watson-developer-cloud)\n  Using cached certifi-2017.11.5-py2.py3-none-any.whl\nCollecting idna<2.7,>=2.5 (from requests<3.0,>=2.0->watson-developer-cloud)\n  Downloading idna-2.6-py2.py3-none-any.whl (56kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 1.8MB/s eta 0:00:01\n\u001b[?25hRequirement already up-to-date: six>=1.5.2 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sfbc-20c2d955c74628-3c618564d05f/.local/lib/python3.5/site-packages (from pyOpenSSL>=16.2.0->watson-developer-cloud)\nCollecting cryptography>=2.1.4 (from pyOpenSSL>=16.2.0->watson-developer-cloud)\n  Downloading cryptography-2.1.4-cp35-cp35m-manylinux1_x86_64.whl (2.2MB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.2MB 340kB/s eta 0:00:01\n\u001b[?25hCollecting cffi>=1.7; platform_python_implementation != \"PyPy\" (from cryptography>=2.1.4->pyOpenSSL>=16.2.0->watson-developer-cloud)\n  Downloading cffi-1.11.2-cp35-cp35m-manylinux1_x86_64.whl (419kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 419kB 965kB/s eta 0:00:01\n\u001b[?25hCollecting asn1crypto>=0.21.0 (from cryptography>=2.1.4->pyOpenSSL>=16.2.0->watson-developer-cloud)\n  Downloading asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 102kB 2.9MB/s ta 0:00:01\n\u001b[?25hCollecting pycparser (from cffi>=1.7; platform_python_implementation != \"PyPy\"->cryptography>=2.1.4->pyOpenSSL>=16.2.0->watson-developer-cloud)\nBuilding wheels for collected packages: watson-developer-cloud, pysolr\n  Running setup.py bdist_wheel for watson-developer-cloud ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /gpfs/fs01/user/sfbc-20c2d955c74628-3c618564d05f/.cache/pip/wheels/4e/db/00/a8e227febd530f4bbc6a4b8d744cdec3400db3dd197c059054\n  Running setup.py bdist_wheel for pysolr ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /gpfs/fs01/user/sfbc-20c2d955c74628-3c618564d05f/.cache/pip/wheels/9a/da/43/dddb8a3089b1d74b183f1ff7244fc6e528289fd6b8e06e083f\nSuccessfully built watson-developer-cloud pysolr\nInstalling collected packages: urllib3, chardet, certifi, idna, requests, pysolr, pycparser, cffi, asn1crypto, cryptography, pyOpenSSL, python-dateutil, watson-developer-cloud\nSuccessfully installed asn1crypto-0.24.0 certifi-2017.11.5 cffi-1.11.2 chardet-3.0.4 cryptography-2.1.4 idna-2.6 pyOpenSSL-17.5.0 pycparser-2.18 pysolr-3.7.0 python-dateutil-2.6.1 requests-2.18.4 urllib3-1.22 watson-developer-cloud-1.0.2\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Install the Beautiful Soup package:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 8, 
            "source": "!pip install --upgrade beautifulsoup4", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Collecting beautifulsoup4\n  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 1.9MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: beautifulsoup4\nSuccessfully installed beautifulsoup4-4.6.0\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Install the PixieDust package, unless you installed PixieDust locally from source and want to continue to run PixieDust from source:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 9, 
            "source": "!pip install --user --upgrade pixiedust", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Collecting pixiedust\n  Downloading pixiedust-1.1.5.tar.gz (158kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 163kB 1.2MB/s eta 0:00:01\n\u001b[?25hCollecting mpld3 (from pixiedust)\n  Downloading mpld3-0.3.tar.gz (788kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 798kB 657kB/s eta 0:00:01\n\u001b[?25hCollecting lxml (from pixiedust)\n  Downloading lxml-4.1.1-cp35-cp35m-manylinux1_x86_64.whl (5.5MB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.5MB 135kB/s eta 0:00:01    25% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                       | 1.4MB 40.3MB/s eta 0:00:01\n\u001b[?25hCollecting geojson (from pixiedust)\n  Downloading geojson-2.3.0-py2.py3-none-any.whl\nCollecting astunparse (from pixiedust)\n  Downloading astunparse-1.5.0-py2.py3-none-any.whl\nCollecting markdown (from pixiedust)\n  Downloading Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 81kB 1.5MB/s eta 0:00:01\n\u001b[?25hCollecting wheel<1.0,>=0.23.0 (from astunparse->pixiedust)\n  Downloading wheel-0.30.0-py2.py3-none-any.whl (49kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 2.4MB/s eta 0:00:01\n\u001b[?25hRequirement already up-to-date: six<2.0,>=1.6.1 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sfbc-20c2d955c74628-3c618564d05f/.local/lib/python3.5/site-packages (from astunparse->pixiedust)\nBuilding wheels for collected packages: pixiedust, mpld3\n  Running setup.py bdist_wheel for pixiedust ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /gpfs/fs01/user/sfbc-20c2d955c74628-3c618564d05f/.cache/pip/wheels/db/06/ca/84ec10196f33a72e0b0603a22c34b644269545ed9427e78a1f\n  Running setup.py bdist_wheel for mpld3 ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /gpfs/fs01/user/sfbc-20c2d955c74628-3c618564d05f/.cache/pip/wheels/69/bc/68/7ca3b696749d183e998968fc24b0ff3c5e119d9e68bf495b07\nSuccessfully built pixiedust mpld3\nInstalling collected packages: mpld3, lxml, geojson, wheel, astunparse, markdown, pixiedust\nSuccessfully installed astunparse-1.5.0 geojson-2.3.0 lxml-4.1.1 markdown-2.6.11 mpld3-0.3 pixiedust-1.1.5 wheel-0.30.0\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Now restart the kernel by choosing **Kernel > Restart**.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "### <a id=\"setup2\"></a>1.2 Import packages and libraries\nImport the packages and libraries that you'll use:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 10, 
            "source": "import json\nimport sys\nimport watson_developer_cloud\nfrom watson_developer_cloud import ToneAnalyzerV3, VisualRecognitionV3\nimport watson_developer_cloud.natural_language_understanding.features.v1 as features\n\nimport operator\nfrom functools import reduce\nfrom io import StringIO\nimport numpy as np\nfrom bs4 import BeautifulSoup as bs\nfrom operator import itemgetter\nfrom os.path import join, dirname\nimport pandas as pd\nimport numpy as np\nimport requests\nimport pixiedust", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Pixiedust database opened successfully\nTable VERSION_TRACKER created successfully\n"
                }, 
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>", 
                        "text/html": "\n        <div style=\"margin:10px\">\n            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n            </a>\n            <span>Pixiedust version 1.1.3</span>\n        </div>\n        "
                    }
                }, 
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Pixiedust runtime updated. Please restart kernel\nTable SPARK_PACKAGES created successfully\nTable USER_PREFERENCES created successfully\nTable service_connections created successfully\n"
                }, 
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>", 
                        "text/html": "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.3, Latest is 1.1.5</div>"
                    }
                }, 
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>", 
                        "text/html": "\n                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n            "
                    }
                }, 
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>", 
                        "text/html": "<div>Please restart kernel after upgrading.</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "### <a id='setup3'></a>1.3 Add your service credentials from Bluemix for the Watson services\n\nYou must create a Watson Natural Language Understanding service, a Watson Tone Analyzer service, and a Watson Visual Recognition service on [Bluemix](bluemix.net).\n\n1. Create a service for [Natural Language Understanding (NLU)](https://www.ibm.com/watson/developercloud/natural-language-understanding.html). \n1. Create a service for [Tone Analyzer](https://console.ng.bluemix.net/catalog/services/tone-analyzer?taxonomyNavigation=watson).\n1. Create a service for [Visual Recognition](https://console.ng.bluemix.net/catalog/services/visual-recognition).\n1. Insert the username and password values for your NLU and Tone Analyzer services and the API key for your Visual Recognition service in the following cell. Do not change the values of the `version` fields.\n1. Run the cell.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 11, 
            "source": "nlu = watson_developer_cloud.NaturalLanguageUnderstandingV1(version='2017-02-27', \n                                                            username='e2c7d38c-511f-4e2e-9237-fab22c666032', \n                                                            password='8W0D4Z03BMu1') \ntone_analyzer = ToneAnalyzerV3(version='2016-05-19', \n                               username='ec13b6a3-52da-4af8-8cff-22afaa47df09', \n                               password='byCunXH1gJTS') \n\nvisual_recognition = VisualRecognitionV3('2016-05-20', api_key='0fbb125b0262ae26e761d88efff117de62fdbda5')", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "## <a id='load'></a> 2. Load the data and set variables\n\nThe data you'll analyzing is a sample of a standard export of the Facebook Insights Post information from the <a href=\"https://www.facebook.com/ibmwatson/\" target=\"_blank\" rel=\"noopener noreferrer\">IBM Watson Facebook page</a>. Engagement metrics such as clicks, impressions, and so on, are altered and do not reflect actual post performance data. The data is on the DSX community page.\n\n### <a id='load1'></a>2.1 Load the data\nTo get the data and load it into a pandas DataFrame:\n\n1. Go to the [Watson Facebook data card](https://apsportal.ibm.com/exchange/public/entry/view/ebaf6aab3f42217a22fb787d296fde9d) and click the download icon to save the file on your computer.\n1. Back in your notebook, load the file by clicking the **Find and Add Data** icon and then dragging and dropping the file onto the pane or browsing for the file. The data is stored in the object storage container that is associated with your project.\n1. Click in the next cell and then choose **Insert to code > Insert Pandas DataFrame** from below the file name and then run the cell.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 12, 
            "source": "# The code was removed by DSX for sharing.", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "execution_count": 12, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "                         \ufeffPost ID  \\\n0  187446750783_10153359024455784   \n1  187446750783_10153215851080784   \n2  187446750783_10153357233820784   \n3  187446750783_10153353697105784   \n4  187446750783_10153351555645784   \n\n                                           Permalink  \\\n0  https://www.facebook.com/ibmwatson/posts/10153...   \n1  https://www.facebook.com/ibmwatson/posts/10153...   \n2  https://www.facebook.com/ibmwatson/posts/10153...   \n3  https://www.facebook.com/ibmwatson/posts/10153...   \n4  https://www.facebook.com/ibmwatson/posts/10153...   \n\n                                        Post Message   Type  Countries  \\\n0  Cheers to a wonderful New Year with Chef Watso...  Photo        NaN   \n1                           IBM Watson's cover photo  Photo        NaN   \n2  What is Watson? IBM Watson is a technology pla...  Photo        NaN   \n3  Did you know that we have been hosting a serie...  Photo        NaN   \n4  Interested in applying social media analytics ...  Photo        NaN   \n\n   Languages           Posted Audience Targeting  Lifetime Post Total Reach  \\\n0        NaN  12/31/2015 6:28                                          2291   \n1        NaN  12/31/2015 6:26                                           158   \n2        NaN  12/30/2015 7:00                                          4203   \n3        NaN  12/28/2015 7:05                                          2847   \n4        NaN  12/27/2015 7:00                                          2514   \n\n   Lifetime Post organic reach  \\\n0                         2291   \n1                          158   \n2                         4203   \n3                         2847   \n4                         2514   \n\n                                  ...                                  \\\n0                                 ...                                   \n1                                 ...                                   \n2                                 ...                                   \n3                                 ...                                   \n4                                 ...                                   \n\n   Lifetime Post consumers by type - photo view  \\\n0                                           4.0   \n1                                         307.0   \n2                                          67.0   \n3                                          62.0   \n4                                          71.0   \n\n   Lifetime Post Consumptions by type - link clicks  \\\n0                                              21.0   \n1                                               NaN   \n2                                              26.0   \n3                                              19.0   \n4                                               6.0   \n\n   Lifetime Post Consumptions by type - other clicks  \\\n0                                               27.0   \n1                                                NaN   \n2                                              102.0   \n3                                               37.0   \n4                                               13.0   \n\n   Lifetime Post Consumptions by type - photo view  \\\n0                                              4.0   \n1                                            544.0   \n2                                             94.0   \n3                                             83.0   \n4                                             97.0   \n\n   Lifetime Negative feedback - hide_all_clicks  \\\n0                                           NaN   \n1                                           NaN   \n2                                           NaN   \n3                                           1.0   \n4                                           NaN   \n\n   Lifetime Negative feedback - hide_clicks  \\\n0                                       NaN   \n1                                       NaN   \n2                                       NaN   \n3                                       NaN   \n4                                       NaN   \n\n   Lifetime Negative feedback - unlike_page_clicks  \\\n0                                              NaN   \n1                                              NaN   \n2                                              NaN   \n3                                              NaN   \n4                                              NaN   \n\n   Lifetime Negative Feedback from Users by Type - hide_all_clicks  \\\n0                                                NaN                 \n1                                                NaN                 \n2                                                NaN                 \n3                                                1.0                 \n4                                                NaN                 \n\n   Lifetime Negative Feedback from Users by Type - hide_clicks  \\\n0                                                NaN             \n1                                                NaN             \n2                                                NaN             \n3                                                NaN             \n4                                                NaN             \n\n   Lifetime Negative Feedback from Users by Type - unlike_page_clicks  \n0                                                NaN                   \n1                                                NaN                   \n2                                                NaN                   \n3                                                NaN                   \n4                                                NaN                   \n\n[5 rows x 52 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>\ufeffPost ID</th>\n      <th>Permalink</th>\n      <th>Post Message</th>\n      <th>Type</th>\n      <th>Countries</th>\n      <th>Languages</th>\n      <th>Posted</th>\n      <th>Audience Targeting</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>Lifetime Post organic reach</th>\n      <th>...</th>\n      <th>Lifetime Post consumers by type - photo view</th>\n      <th>Lifetime Post Consumptions by type - link clicks</th>\n      <th>Lifetime Post Consumptions by type - other clicks</th>\n      <th>Lifetime Post Consumptions by type - photo view</th>\n      <th>Lifetime Negative feedback - hide_all_clicks</th>\n      <th>Lifetime Negative feedback - hide_clicks</th>\n      <th>Lifetime Negative feedback - unlike_page_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_all_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - unlike_page_clicks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>187446750783_10153359024455784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Cheers to a wonderful New Year with Chef Watso...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/31/2015 6:28</td>\n      <td></td>\n      <td>2291</td>\n      <td>2291</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>21.0</td>\n      <td>27.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>187446750783_10153215851080784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>IBM Watson's cover photo</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/31/2015 6:26</td>\n      <td></td>\n      <td>158</td>\n      <td>158</td>\n      <td>...</td>\n      <td>307.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>544.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>187446750783_10153357233820784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>What is Watson? IBM Watson is a technology pla...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/30/2015 7:00</td>\n      <td></td>\n      <td>4203</td>\n      <td>4203</td>\n      <td>...</td>\n      <td>67.0</td>\n      <td>26.0</td>\n      <td>102.0</td>\n      <td>94.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>187446750783_10153353697105784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Did you know that we have been hosting a serie...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/28/2015 7:05</td>\n      <td></td>\n      <td>2847</td>\n      <td>2847</td>\n      <td>...</td>\n      <td>62.0</td>\n      <td>19.0</td>\n      <td>37.0</td>\n      <td>83.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>187446750783_10153351555645784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Interested in applying social media analytics ...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/27/2015 7:00</td>\n      <td></td>\n      <td>2514</td>\n      <td>2514</td>\n      <td>...</td>\n      <td>71.0</td>\n      <td>6.0</td>\n      <td>13.0</td>\n      <td>97.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 52 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "### <a id='load2'></a>2.2 Set variables\nYou need to set these variables:\n - The name of the DataFrame\n - Your credentials for the source file\n - A file name for the enriched DataFrame\n \nDefine a variable, `df`, for the DataFrame that you just created. If necessary, change the original DataFrame name to match the one you created.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 13, 
            "source": "df = df_data_3", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "You'll need to use your credentials when you save the DataFrame to a file.\n\nTo define a credentials variable:\n 1. Click in the cell below.\n 2. On the **Files** pane, choose **Insert to code > Insert Credentials** from below the orginal file name. \n 3. Make sure the name of the variable is `credentials_1` in the first line and then run the cell.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 14, 
            "source": "# The code was removed by DSX for sharing.", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "You'll save the enriched data to your project object storage. Give the file a name:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 15, 
            "source": "# replace YOUR FILE NAME with a file name \nlocalfilename = 'Essilor Demo'", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "## <a id='prepare'></a>3. Prepare the data\n\nYou'll prepare the data by cleansing it and extracting the URLs. Many of the posts contain both text and a URL. The first task is to separate URLs from the text so that they can be analyzed separately. Then you need to get thumbnails for the photos and links, and convert any shortened URLs to full URLs.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "### <a id='prepare1'></a> 3.1 Cleanse the data\nTo cleanse the data, you'll rename a column and add a column with the URLs that were embedded in the post. \n\nChange the name of the `Post Message` column to `Text`:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 16, 
            "source": "df.rename(columns={'Post Message': 'Text'}, inplace=True)", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 17, 
            "source": "df = df.drop([0])\ndf.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 17, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "                         \ufeffPost ID  \\\n1  187446750783_10153215851080784   \n2  187446750783_10153357233820784   \n3  187446750783_10153353697105784   \n4  187446750783_10153351555645784   \n5  187446750783_10153348958265784   \n\n                                           Permalink  \\\n1  https://www.facebook.com/ibmwatson/posts/10153...   \n2  https://www.facebook.com/ibmwatson/posts/10153...   \n3  https://www.facebook.com/ibmwatson/posts/10153...   \n4  https://www.facebook.com/ibmwatson/posts/10153...   \n5  https://www.facebook.com/ibmwatson/posts/10153...   \n\n                                                Text   Type  Countries  \\\n1                           IBM Watson's cover photo  Photo        NaN   \n2  What is Watson? IBM Watson is a technology pla...  Photo        NaN   \n3  Did you know that we have been hosting a serie...  Photo        NaN   \n4  Interested in applying social media analytics ...  Photo        NaN   \n5  Using the Personality Insights API from the Wa...  Photo        NaN   \n\n   Languages            Posted Audience Targeting  Lifetime Post Total Reach  \\\n1        NaN   12/31/2015 6:26                                           158   \n2        NaN   12/30/2015 7:00                                          4203   \n3        NaN   12/28/2015 7:05                                          2847   \n4        NaN   12/27/2015 7:00                                          2514   \n5        NaN  12/26/2015 10:20                                          5873   \n\n   Lifetime Post organic reach  \\\n1                          158   \n2                         4203   \n3                         2847   \n4                         2514   \n5                         5873   \n\n                                  ...                                  \\\n1                                 ...                                   \n2                                 ...                                   \n3                                 ...                                   \n4                                 ...                                   \n5                                 ...                                   \n\n   Lifetime Post consumers by type - photo view  \\\n1                                         307.0   \n2                                          67.0   \n3                                          62.0   \n4                                          71.0   \n5                                         226.0   \n\n   Lifetime Post Consumptions by type - link clicks  \\\n1                                               NaN   \n2                                              26.0   \n3                                              19.0   \n4                                               6.0   \n5                                             116.0   \n\n   Lifetime Post Consumptions by type - other clicks  \\\n1                                                NaN   \n2                                              102.0   \n3                                               37.0   \n4                                               13.0   \n5                                              214.0   \n\n   Lifetime Post Consumptions by type - photo view  \\\n1                                            544.0   \n2                                             94.0   \n3                                             83.0   \n4                                             97.0   \n5                                            326.0   \n\n   Lifetime Negative feedback - hide_all_clicks  \\\n1                                           NaN   \n2                                           NaN   \n3                                           1.0   \n4                                           NaN   \n5                                           NaN   \n\n   Lifetime Negative feedback - hide_clicks  \\\n1                                       NaN   \n2                                       NaN   \n3                                       NaN   \n4                                       NaN   \n5                                       1.0   \n\n   Lifetime Negative feedback - unlike_page_clicks  \\\n1                                              NaN   \n2                                              NaN   \n3                                              NaN   \n4                                              NaN   \n5                                              NaN   \n\n   Lifetime Negative Feedback from Users by Type - hide_all_clicks  \\\n1                                                NaN                 \n2                                                NaN                 \n3                                                1.0                 \n4                                                NaN                 \n5                                                NaN                 \n\n   Lifetime Negative Feedback from Users by Type - hide_clicks  \\\n1                                                NaN             \n2                                                NaN             \n3                                                NaN             \n4                                                NaN             \n5                                                1.0             \n\n   Lifetime Negative Feedback from Users by Type - unlike_page_clicks  \n1                                                NaN                   \n2                                                NaN                   \n3                                                NaN                   \n4                                                NaN                   \n5                                                NaN                   \n\n[5 rows x 52 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>\ufeffPost ID</th>\n      <th>Permalink</th>\n      <th>Text</th>\n      <th>Type</th>\n      <th>Countries</th>\n      <th>Languages</th>\n      <th>Posted</th>\n      <th>Audience Targeting</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>Lifetime Post organic reach</th>\n      <th>...</th>\n      <th>Lifetime Post consumers by type - photo view</th>\n      <th>Lifetime Post Consumptions by type - link clicks</th>\n      <th>Lifetime Post Consumptions by type - other clicks</th>\n      <th>Lifetime Post Consumptions by type - photo view</th>\n      <th>Lifetime Negative feedback - hide_all_clicks</th>\n      <th>Lifetime Negative feedback - hide_clicks</th>\n      <th>Lifetime Negative feedback - unlike_page_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_all_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - unlike_page_clicks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>187446750783_10153215851080784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>IBM Watson's cover photo</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/31/2015 6:26</td>\n      <td></td>\n      <td>158</td>\n      <td>158</td>\n      <td>...</td>\n      <td>307.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>544.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>187446750783_10153357233820784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>What is Watson? IBM Watson is a technology pla...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/30/2015 7:00</td>\n      <td></td>\n      <td>4203</td>\n      <td>4203</td>\n      <td>...</td>\n      <td>67.0</td>\n      <td>26.0</td>\n      <td>102.0</td>\n      <td>94.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>187446750783_10153353697105784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Did you know that we have been hosting a serie...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/28/2015 7:05</td>\n      <td></td>\n      <td>2847</td>\n      <td>2847</td>\n      <td>...</td>\n      <td>62.0</td>\n      <td>19.0</td>\n      <td>37.0</td>\n      <td>83.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>187446750783_10153351555645784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Interested in applying social media analytics ...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/27/2015 7:00</td>\n      <td></td>\n      <td>2514</td>\n      <td>2514</td>\n      <td>...</td>\n      <td>71.0</td>\n      <td>6.0</td>\n      <td>13.0</td>\n      <td>97.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>187446750783_10153348958265784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Using the Personality Insights API from the Wa...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/26/2015 10:20</td>\n      <td></td>\n      <td>5873</td>\n      <td>5873</td>\n      <td>...</td>\n      <td>226.0</td>\n      <td>116.0</td>\n      <td>214.0</td>\n      <td>326.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 52 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Use the `str.partition` function to remove strings that contain \"http\" and \"www\" from the `Text` column and save them in new DataFrames, then add all web addresses to a new `Link` column in the original DataFrame. This process captures all web addresses: https, http, and www.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 18, 
            "source": "df_http= df[\"Text\"].str.partition(\"http\")\ndf_www = df[\"Text\"].str.partition(\"www\")\n\n#combine delimiters with actual links\ndf_http[\"Link\"] = df_http[1].map(str) + df_http[2]\ndf_www[\"Link1\"] = df_www[1].map(str) + df_www[2]\n\n#include only Link columns \ndf_http.drop(df_http.columns[0:3], axis=1, inplace = True)\ndf_www.drop(df_www.columns[0:3], axis=1, inplace = True)\n\n#merge http and www dataframes\ndfmerge = pd.concat([df_http, df_www], axis=1)\n\n#the following steps will allow you to merge data columns from the left to the right\ndfmerge = dfmerge.apply(lambda x: x.str.strip()).replace('', np.nan)\n\n#use fillna to fill any blanks with the Link1 column\ndfmerge[\"Link\"].fillna(dfmerge[\"Link1\"], inplace = True)\n\n#delete Link1 (www column)\ndfmerge.drop(\"Link1\", axis=1, inplace = True)\n\n#combine Link data frame \ndf = pd.concat([dfmerge,df], axis = 1)\n\n# # make sure text column is a string\ndf[\"Text\"] = df[\"Text\"].astype(\"str\")\n\n# #strip links from Text column\ndf['Text'] = df['Text'].apply(lambda x: x.split('http')[0])\ndf['Text'] = df['Text'].apply(lambda x: x.split('www')[0])\n", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "### <a id='prepare2'></a> 3.2 Extract thumbnails and extended links\n\nA standard Facebook export does not provide the thumbnail that usually summarizes the link or photo associated with each post. Use the Beautiful Soup library to go into the HTML of the post and extract the thumbnail text:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 19, 
            "source": "#Pull thumbnail descriptions using beautiful soup\n#changes links from objects to strings\nfor link in df.Link:\n    df.Link.to_string()\n    \n#create empty list to store descriptions    \ndescription = []\n\n#use BeautifulSoup to pull descriptions from links \nfor url in df[\"Link\"]:\n    try:\n        #if there's no description\n        if pd.isnull(url):\n            description.append(\"\")\n        else:\n            page3= requests.get(url)\n            soup3= bs(page3.text,\"lxml\")\n            #Capture both capatalized 'Description' and lower case\n            desc= soup3.find(attrs={'name':'Description'})\n            if desc == None:\n                desc= soup3.find(attrs={'name':'description'})\n            description.append(desc['content'])\n            \n    #this exception will save you from 404 errors\n    except Exception:\n        description.append(\"\")\n        continue\n        \n#save to df and add column titled 'Thumbnails'\ndf[\"Thumbnails\"] = description\n#df['Thumbnails'].head()\n#df.head()", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "Show the first five thumbnails:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 20, 
            "source": "df['Thumbnails'].head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 20, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "1                                                     \n2              Watson is the AI platform for business.\n3    Get insights on building with Watson APIs and ...\n4    The page you requested cannot be displayed (HT...\n5    For more than a century IBM has been dedicated...\nName: Thumbnails, dtype: object"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Use the Beautiful Soup library to find the images in posts and save them in a new column:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 21, 
            "source": "piclinks = []\n\nfor url in df[\"Link\"]:\n    try:\n        if pd.isnull(url):\n            piclinks.append(\"\")\n        else: \n            page3= requests.get(url)\n            soup3= bs(page3.text,\"lxml\")\n            pic = soup3.find('meta', property =\"og:image\")\n            if pic:\n                piclinks.append(pic[\"content\"])\n            else: \n                piclinks.append(\"\")\n    except:\n        piclinks.append(\"\")\ndf[\"Image\"] = piclinks ", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "The Natural Language Understanding service requires full URLs. However, many of the Watson Facebook posts include shortened URLs.\n\nUse the Beautiful Soup library to find the full URLs and save them in a new column:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 22, 
            "source": "#convert shortened links to their original form\n\nshortlink = df[\"Link\"]\nextendedlink = []\n\nfor link in shortlink:\n    #create empty list to store   \n    try:\n        extended_link = requests.Session().head(link, allow_redirects=True).url\n        extendedlink.append(extended_link)\n    except:\n         # catch *all* exceptions\n        e = sys.exc_info()[0]\n        extendedlink.append('')\n        pass\ndf[\"Extended Links\"] = extendedlink", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "## <a id='enrich'></a> 4. Enrich the data\n\nIt's enrichment time! \n\nFirst you'll run NLU scripts to add keywords and entities information for the post text, the thumbnails text, and the text from linked articles. Then you'll run Tone Analyzer scripts to gather the top social, writing, and emotion tones from the post text and the text from linked articles. And finally, you'll run a Visual Recognition script to classify the images.\n\n### <a id='enrich1'></a> 4.1 Enrich the post text with NLU\nThe following script is an example of how to use Natural Language Understanding to iterate through each post and extract enrichment features for future analysis.\n\nFor this example, `free_form_responses` is set the `Text` column in our DataFrame, which contains the text of each post. NLU can also iterate through a column of URLs, or other freeform text. There's a list within a list for the Keywords and Entities features to allow gathering multiple entities and keywords from each piece of text.\n\nEach extracted feature is appended to the DataFrame in a new column that's defined at the end of the script. If you want to run this same script for the other columns, set `free_form_responses` to the column name, if you are using URLs, change the `text=response` parameter to `url=response`, and update the new column names as necessary. ", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 23, 
            "source": "# Extract the free form text response from the DataFrame\n# If you are using this script for a different CSV, change this column name\nfree_form_responses = df['Text']\n# define the list of enrichments to apply\n# if you are modifying this script, add or remove the enrichments as needed\nf = [features.Entities(), features.Keywords(),features.Emotion(),features.Sentiment()]#'typed-rels'\n\n# Create a list to store the enriched data\noverallSentimentScore = []\noverallSentimentType = []\nhighestEmotion = []\nhighestEmotionScore = []\nkywords = []\nentities = []\n\n# Go thru every reponse and enrich the text using NLU\nfor idx, response in enumerate(free_form_responses):\n    #print(\"Processing record number: \", idx, \" and text: \", response)\n    try:\n        enriched_json = json.loads(json.dumps(nlu.analyze(text=response, features=f)))\n        #print(enriched_json)\n\n        # get the SENTIMENT score and type\n        if 'sentiment' in enriched_json:\n            if('score' in enriched_json['sentiment'][\"document\"]):\n                overallSentimentScore.append(enriched_json[\"sentiment\"][\"document\"][\"score\"])\n            else:\n                overallSentimentScore.append('0')\n\n            if('label' in enriched_json['sentiment'][\"document\"]):\n                overallSentimentType.append(enriched_json[\"sentiment\"][\"document\"][\"label\"])\n            else:\n                overallSentimentType.append('0')\n\n        # read the EMOTIONS into a dict and get the key (emotion) with maximum value\n        if 'emotion' in enriched_json:\n            me = max(enriched_json[\"emotion\"][\"document\"][\"emotion\"].items(), key=operator.itemgetter(1))[0]\n            highestEmotion.append(me)\n            highestEmotionScore.append(enriched_json[\"emotion\"][\"document\"][\"emotion\"][me])\n\n        else:\n            highestEmotion.append(\"\")\n            highestEmotionScore.append(\"\")\n\n        #iterate and get KEYWORDS with a confidence of over 50%\n        if 'keywords' in enriched_json:\n            #print((enriched_json['keywords']))\n            tmpkw = []\n            for kw in enriched_json['keywords']:\n                if(float(kw[\"relevance\"]) >= 0.5):\n                    #print(\"kw is: \", kw, \"and val is \", kw[\"text\"])\n                    tmpkw.append(kw[\"text\"])#str(kw[\"text\"]).strip('[]')\n            #convert multiple keywords in a list to a string\n            if(len(tmpkw) > 1):\n                tmpkw = \"\".join(reduce(lambda a, b: a + ', ' + b, tmpkw))\n            elif(len(tmpkw) == 0):\n                tmpkw = \"\"\n            else:\n                tmpkw = \"\".join(reduce(lambda a, b='': a + b , tmpkw))\n            kywords.append(tmpkw)\n        else:\n            kywords.append(\"\")\n            \n        #iterate and get Entities with a confidence of over 30%\n        if 'entities' in enriched_json:\n            #print((enriched_json['entities']))\n            tmpent = []\n            for ent in enriched_json['entities']:\n                \n                if(float(ent[\"relevance\"]) >= 0.3):\n                    tmpent.append(ent[\"type\"])\n            #convert multiple concepts in a list to a string\n            if(len(tmpent) > 1):\n                tmpent = \"\".join(reduce(lambda a, b: a + ', ' + b, tmpent))\n            elif(len(tmpent) == 0):\n                tmpent = \"\"\n            else:\n                tmpent = \"\".join(reduce(lambda a, b='': a + b , tmpent))\n            entities.append(tmpent)\n        else:\n            entities.append(\"\")    \n            \n    except:\n        # catch *all* exceptions\n        e = sys.exc_info()[0]\n        overallSentimentScore.append(' ')\n        overallSentimentType.append(' ')\n        highestEmotion.append(' ')\n        highestEmotionScore.append(' ')\n        kywords.append(' ')\n        entities.append(' ')\n        pass\n    \n# Create columns from the list and append to the DataFrame\nif highestEmotion:\n    df['TextHighestEmotion'] = highestEmotion\nif highestEmotionScore:\n    df['TextHighestEmotionScore'] = highestEmotionScore\n\nif overallSentimentType:\n    df['TextOverallSentimentType'] = overallSentimentType\nif overallSentimentScore:\n    df['TextOverallSentimentScore'] = overallSentimentScore\n\ndf['TextKeywords'] = kywords\ndf['TextEntities'] = entities\n", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "Now you have a column with multiple keywords and entities, separated by commas. For your analysis in Part II, you'll need the top keyword and entity for each post. \nAdd two new columns to capture the `MaxTextKeyword` and `MaxTextEntity`:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 24, 
            "source": "#choose first of Keywords,Concepts, Entities\ndf[\"MaxTextKeywords\"] = df[\"TextKeywords\"].apply(lambda x: x.split(',')[0])\ndf[\"MaxTextEntity\"] = df[\"TextEntities\"].apply(lambda x: x.split(',')[0])\ndf.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 24, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "                                     Link                        \ufeffPost ID  \\\n1                                     NaN  187446750783_10153215851080784   \n2                   http://ibm.co/1mngjQu  187446750783_10153357233820784   \n3                   http://ibm.co/1IyCTpX  187446750783_10153353697105784   \n4                http://ibm.co/fb_1XVBwbz  187446750783_10153351555645784   \n5  http://ibm.co/1IvPJFx via Fast Company  187446750783_10153348958265784   \n\n                                           Permalink  \\\n1  https://www.facebook.com/ibmwatson/posts/10153...   \n2  https://www.facebook.com/ibmwatson/posts/10153...   \n3  https://www.facebook.com/ibmwatson/posts/10153...   \n4  https://www.facebook.com/ibmwatson/posts/10153...   \n5  https://www.facebook.com/ibmwatson/posts/10153...   \n\n                                                Text   Type  Countries  \\\n1                           IBM Watson's cover photo  Photo        NaN   \n2  What is Watson? IBM Watson is a technology pla...  Photo        NaN   \n3  Did you know that we have been hosting a serie...  Photo        NaN   \n4  Interested in applying social media analytics ...  Photo        NaN   \n5  Using the Personality Insights API from the Wa...  Photo        NaN   \n\n   Languages            Posted Audience Targeting  Lifetime Post Total Reach  \\\n1        NaN   12/31/2015 6:26                                           158   \n2        NaN   12/30/2015 7:00                                          4203   \n3        NaN   12/28/2015 7:05                                          2847   \n4        NaN   12/27/2015 7:00                                          2514   \n5        NaN  12/26/2015 10:20                                          5873   \n\n       ...                                                    Image  \\\n1      ...                                                            \n2      ...                                                            \n3      ...        http://www.ibm.com/watson/assets/img/cloud/her...   \n4      ...                                                            \n5      ...                                                            \n\n                                      Extended Links  TextHighestEmotion  \\\n1                                                                          \n2                        https://www.ibm.com/watson/                       \n3  http://www.pages03.net/ibmwatson/building-with...                       \n4  https://www-304.ibm.com/connections/blogs/pred...                       \n5                         https://www.ibm.com/us-en/                       \n\n   TextHighestEmotionScore  TextOverallSentimentType  \\\n1                                                      \n2                                                      \n3                                                      \n4                                                      \n5                                                      \n\n   TextOverallSentimentScore  TextKeywords  TextEntities  MaxTextKeywords  \\\n1                                                                           \n2                                                                           \n3                                                                           \n4                                                                           \n5                                                                           \n\n   MaxTextEntity  \n1                 \n2                 \n3                 \n4                 \n5                 \n\n[5 rows x 64 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Link</th>\n      <th>\ufeffPost ID</th>\n      <th>Permalink</th>\n      <th>Text</th>\n      <th>Type</th>\n      <th>Countries</th>\n      <th>Languages</th>\n      <th>Posted</th>\n      <th>Audience Targeting</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>...</th>\n      <th>Image</th>\n      <th>Extended Links</th>\n      <th>TextHighestEmotion</th>\n      <th>TextHighestEmotionScore</th>\n      <th>TextOverallSentimentType</th>\n      <th>TextOverallSentimentScore</th>\n      <th>TextKeywords</th>\n      <th>TextEntities</th>\n      <th>MaxTextKeywords</th>\n      <th>MaxTextEntity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>187446750783_10153215851080784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>IBM Watson's cover photo</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/31/2015 6:26</td>\n      <td></td>\n      <td>158</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://ibm.co/1mngjQu</td>\n      <td>187446750783_10153357233820784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>What is Watson? IBM Watson is a technology pla...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/30/2015 7:00</td>\n      <td></td>\n      <td>4203</td>\n      <td>...</td>\n      <td></td>\n      <td>https://www.ibm.com/watson/</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://ibm.co/1IyCTpX</td>\n      <td>187446750783_10153353697105784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Did you know that we have been hosting a serie...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/28/2015 7:05</td>\n      <td></td>\n      <td>2847</td>\n      <td>...</td>\n      <td>http://www.ibm.com/watson/assets/img/cloud/her...</td>\n      <td>http://www.pages03.net/ibmwatson/building-with...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://ibm.co/fb_1XVBwbz</td>\n      <td>187446750783_10153351555645784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Interested in applying social media analytics ...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/27/2015 7:00</td>\n      <td></td>\n      <td>2514</td>\n      <td>...</td>\n      <td></td>\n      <td>https://www-304.ibm.com/connections/blogs/pred...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>http://ibm.co/1IvPJFx via Fast Company</td>\n      <td>187446750783_10153348958265784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Using the Personality Insights API from the Wa...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/26/2015 10:20</td>\n      <td></td>\n      <td>5873</td>\n      <td>...</td>\n      <td></td>\n      <td>https://www.ibm.com/us-en/</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 64 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Make sure the new columns have values. If they don't, check your NLU credentials in step 1.3.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "### <a id='enrich2'></a> 4.2 Enrich thumbnail text with NLU \nRun the NLU script on the thumbnail text. \n\nSet `free_form_responses` to the `Thumbnails` column in our DataFrame, which contains the thumbnail text of each post.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 25, 
            "source": "# Extract the thumbnail text from the DataFrame\n# If you are using this script for a different CSV, change this column name\nfree_form_responses= df['Thumbnails']\n# define the list of enrichments to apply\n# if you are modifying this script, add or remove the enrichments as needed\nf = [features.Entities(), features.Keywords(),features.Emotion(),features.Sentiment()]#'typed-rels'\n\n# Create a list to store the enriched data\noverallSentimentScore = []\noverallSentimentType = []\nhighestEmotion = []\nhighestEmotionScore = []\nkywords = []\nentities = []\n\n\n# Go thru every reponse and enrich the text using NLU\nfor idx, response in enumerate(free_form_responses):\n    #print(\"Processing record number: \", idx, \" and text: \", response)\n    try:\n        enriched_json = json.loads(json.dumps(nlu.analyze(text=response, features=f)))\n        #print(enriched_json)\n\n        # get the SENTIMENT score and type\n        if 'sentiment' in enriched_json:\n            if('score' in enriched_json['sentiment'][\"document\"]):\n                overallSentimentScore.append(enriched_json[\"sentiment\"][\"document\"][\"score\"])\n            else:\n                overallSentimentScore.append(\"\")\n\n            if('label' in enriched_json['sentiment'][\"document\"]):\n                overallSentimentType.append(enriched_json[\"sentiment\"][\"document\"][\"label\"])\n            else:\n                overallSentimentType.append(\"\")\n\n        # read the EMOTIONS into a dict and get the key (emotion) with maximum value\n        if 'emotion' in enriched_json:\n            me = max(enriched_json[\"emotion\"][\"document\"][\"emotion\"].items(), key=operator.itemgetter(1))[0]\n            highestEmotion.append(me)\n            highestEmotionScore.append(enriched_json[\"emotion\"][\"document\"][\"emotion\"][me])\n\n        else:\n            highestEmotion.append(\"\")\n            highestEmotionScore.append(\"\")\n\n        #iterate and get KEYWORDS with a confidence of over 50%\n        if 'keywords' in enriched_json:\n            #print((enriched_json['keywords']))\n            tmpkw = []\n            for kw in enriched_json['keywords']:\n                if(float(kw[\"relevance\"]) >= 0.5):\n                    #print(\"kw is: \", kw, \"and val is \", kw[\"text\"])\n                    tmpkw.append(kw[\"text\"])#str(kw[\"text\"]).strip('[]')\n            #convert multiple keywords in a list to a string\n            if(len(tmpkw) > 1):\n                tmpkw = \"\".join(reduce(lambda a, b: a + ', ' + b, tmpkw))\n            elif(len(tmpkw) == 0):\n                tmpkw = \"\"\n            else:\n                tmpkw = \"\".join(reduce(lambda a, b='': a + b , tmpkw))\n            kywords.append(tmpkw)\n\n            \n        #iterate and get Entities with a confidence of over 30%\n        if 'entities' in enriched_json:\n            #print((enriched_json['entities']))\n            tmpent = []\n            for ent in enriched_json['entities']:\n                \n                if(float(ent[\"relevance\"]) >= 0.3):\n                    tmpent.append(ent[\"type\"])\n            #convert multiple concepts in a list to a string\n            if(len(tmpent) > 1):\n                tmpent = \"\".join(reduce(lambda a, b: a + ', ' + b, tmpent))\n            elif(len(tmpent) == 0):\n                tmpent = \"\"\n            else:\n                tmpent = \"\".join(reduce(lambda a, b='': a + b , tmpent))\n            entities.append(tmpent)\n        else:\n            entities.append(\"\")  \n    \n            \n    except:\n        # catch *all* exceptions\n        e = sys.exc_info()[0]\n        overallSentimentScore.append(' ')\n        overallSentimentType.append(' ')\n        highestEmotion.append(' ')\n        highestEmotionScore.append(' ')\n        kywords.append(' ')\n        entities.append(' ')\n        pass\n\n# print(len(highestEmotion))\n# print(len(highestEmotionScore))\n# print(len(overallSentimentType))\n# print(len(overallSentimentScore))\n# print(len(kywords))\n# print(len(entities))\n    \n# Create columns from the list and append to the DataFrame\nif highestEmotion:\n    df['ThumbnailHighestEmotion'] = highestEmotion\nif highestEmotionScore:\n    df['ThumbnailHighestEmotionScore'] = highestEmotionScore\n\nif overallSentimentType:\n    df['ThumbnailOverallSentimentType'] = overallSentimentType\nif overallSentimentScore:\n    df['ThumbnailOverallSentimentScore'] = overallSentimentScore\n\ndf['ThumbnailKeywords'] = kywords\ndf['ThumbnailEntities'] = entities", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": " Add two new columns to capture the `MaxThumbnailKeyword` and `MaxThumbnailEntity`:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 26, 
            "source": "#choose first of Keywords,Concepts,Entities\ndf[\"MaxThumbnailKeywords\"] = df[\"ThumbnailKeywords\"].apply(lambda x: x.split(',')[0])\ndf[\"MaxThumbnailEntity\"] = df[\"ThumbnailEntities\"].apply(lambda x: x.split(',')[0])\n# df.head()", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "### <a id='enrich3'></a> 4.3 Enrich article text with NLU\nRun the NLU script on the article text in the extended links. \n\nSet `free_form_responses` to the `Extended Links` column in our DataFrame, which contains the article text that's linked to in each post.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 27, 
            "source": "# Run links through NLU and return Titles, and NLU Enrichment on full articles\n# If you are using this script for a different CSV, change this column name\nfree_form_responses = df['Extended Links']\n# define the list of enrichments to apply\n# if you are modifying this script, add or remove the enrichments as needed\nf = [features.Entities(), features.Keywords(),features.Emotion(),features.Sentiment()]#'typed-rels'\n\n# Create a list to store the enriched data\noverallSentimentScore = []\noverallSentimentType = []\nhighestEmotion = []\nhighestEmotionScore = []\nkywords = []\nentities = []\n\n\n\n        \n# Go thru every reponse and enrich the text using NLU\nfor idx, response in enumerate(free_form_responses):\n    #print(\"Processing record number: \", idx, \" and text: \", response)\n    try:\n        enriched_json = json.loads(json.dumps(nlu.analyze(url=response, features=f)))\n        #print(enriched_json)\n\n        # get the SENTIMENT score and type\n        if 'sentiment' in enriched_json:\n            if('score' in enriched_json['sentiment'][\"document\"]):\n                overallSentimentScore.append(enriched_json[\"sentiment\"][\"document\"][\"score\"])\n            else:\n                overallSentimentScore.append('None')\n\n            if('label' in enriched_json['sentiment'][\"document\"]):\n                overallSentimentType.append(enriched_json[\"sentiment\"][\"document\"][\"label\"])\n            else:\n                overallSentimentType.append('')\n\n        # read the EMOTIONS into a dict and get the key (emotion) with maximum value\n        if 'emotion' in enriched_json:\n            me = max(enriched_json[\"emotion\"][\"document\"][\"emotion\"].items(), key=operator.itemgetter(1))[0]\n            highestEmotion.append(me)\n            highestEmotionScore.append(enriched_json[\"emotion\"][\"document\"][\"emotion\"][me])\n\n        else:\n            highestEmotion.append('')\n            highestEmotionScore.append('')\n\n        #iterate and get KEYWORDS with a confidence of over 50%\n        if 'keywords' in enriched_json:\n            #print((enriched_json['keywords']))\n            tmpkw = []\n            for kw in enriched_json['keywords']:\n                if(float(kw[\"relevance\"]) >= 0.5):\n                    #print(\"kw is: \", kw, \"and val is \", kw[\"text\"])\n                    tmpkw.append(kw[\"text\"])#str(kw[\"text\"]).strip('[]')\n            #convert multiple keywords in a list to a string\n            if(len(tmpkw) > 1):\n                tmpkw = \"\".join(reduce(lambda a, b: a + ', ' + b, tmpkw))\n            elif(len(tmpkw) == 0):\n                tmpkw = \"\"\n            else:\n                tmpkw = \"\".join(reduce(lambda a, b='': a + b , tmpkw))\n            kywords.append(tmpkw)\n        else: \n            kywords.append(\"\")\n            \n        #iterate and get Entities with a confidence of over 30%\n        if 'entities' in enriched_json:\n            #print((enriched_json['entities']))\n            tmpent = []\n            for ent in enriched_json['entities']:\n                \n                if(float(ent[\"relevance\"]) >= 0.3):\n                    tmpent.append(ent[\"type\"])\n            #convert multiple concepts in a list to a string\n            if(len(tmpent) > 1):\n                tmpent = \"\".join(reduce(lambda a, b: a + ', ' + b, tmpent))\n            elif(len(tmpent) == 0):\n                tmpent = \"\"\n            else:\n                tmpent = \"\".join(reduce(lambda a, b='': a + b , tmpent))\n            entities.append(tmpent)\n        else:\n            entities.append(\"\")\n    \n            \n    except:\n        # catch *all* exceptions\n        e = sys.exc_info()[0]\n        overallSentimentScore.append(' ')\n        overallSentimentType.append(' ')\n        highestEmotion.append(' ')\n        highestEmotionScore.append(' ')\n        kywords.append(' ')\n#       concepts.append(' ')\n        entities.append(' ')\n\n        pass\n\n# print(len(highestEmotion))\n# print(len(highestEmotionScore))\n# print(len(overallSentimentType))\n# print(len(overallSentimentScore))\n# print(len(kywords))\n\n# print(len(entities))\n    \n# Create columns from the list and append to the DataFrame\nif highestEmotion:\n    df['LinkHighestEmotion'] = highestEmotion\nif highestEmotionScore:\n    df['LinkHighestEmotionScore'] = highestEmotionScore\n\nif overallSentimentType:\n    df['LinkOverallSentimentType'] = overallSentimentType\nif overallSentimentScore:\n    df['LinkOverallSentimentScore'] = overallSentimentScore\n\ndf['LinkKeywords'] = kywords\n# df['TextConcepts'] = concepts\ndf['LinkEntities'] = entities", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "Add two new columns to capture the `MaxLinkKeyword` and `MaxLinkEntity`:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 28, 
            "source": "df[\"MaxLinkKeywords\"] = df[\"LinkKeywords\"].apply(lambda x: x.split(',')[0])\ndf[\"MaxLinkEntity\"] = df[\"LinkEntities\"].apply(lambda x: x.split(',')[0])\n#df.head()", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "### <a id='tonepost'></a> 4.4 Run the Tone Analyzer on the post text\nNow use the Tone Analyzer to gather the top social, writing, and emotion tones from the post text and append them, along with their respective scores, to the DataFrame. \n\nSet `free_form_responses` to the `Text` column:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 29, 
            "source": "# Extract the free form text response from the DataFrame\n# If you are using this script for a different CSV, change this column name\nfree_form_responses = df['Text']\n\n#Create a list to store the enriched data\n\nhighestEmotionTone = []\nemotionToneScore = []\n\nlanguageToneScore = []\nhighestLanguageTone = []\n\nsocialToneScore = []\nhighestSocialTone = []\n\n\nfor idx, response in enumerate(free_form_responses):\n    #print(\"Processing record number: \", idx, \" and text: \", response)\n    try:\n        enriched_json = json.loads(json.dumps(tone_analyzer.tone(text=response)))\n        #print(enriched_json)\n        \n        if 'tone_categories' in enriched_json['document_tone']:\n            me = max(enriched_json[\"document_tone\"][\"tone_categories\"][0][\"tones\"], key = itemgetter('score'))['tone_name']      \n            highestEmotionTone.append(me)\n            you = max(enriched_json[\"document_tone\"][\"tone_categories\"][0][\"tones\"], key = itemgetter('score'))['score']\n            emotionToneScore.append(you)\n            \n            me1 = max(enriched_json[\"document_tone\"][\"tone_categories\"][1][\"tones\"], key = itemgetter('score'))['tone_name']      \n            highestLanguageTone.append(me1)\n            you1 = max(enriched_json[\"document_tone\"][\"tone_categories\"][1][\"tones\"], key = itemgetter('score'))['score']\n            languageToneScore.append(you1)\n            \n            me2 = max(enriched_json[\"document_tone\"][\"tone_categories\"][2][\"tones\"], key = itemgetter('score'))['tone_name']      \n            highestSocialTone.append(me2)\n            you2 = max(enriched_json[\"document_tone\"][\"tone_categories\"][2][\"tones\"], key = itemgetter('score'))['score']\n            socialToneScore.append(you2)\n            \n            \n            \n    except:\n        # catch *all* exceptions\n        e = sys.exc_info()[0]\n        emotionToneScore.append(' ')\n        highestEmotionTone.append(' ')\n        languageToneScore.append(' ')\n        highestLanguageTone.append(' ')\n        socialToneScore.append(' ')\n        highestSocialTone.append(' ')\n        pass\n    \nif highestEmotionTone:\n    df['highestEmotionTone'] = highestEmotionTone    \nif emotionToneScore:\n    df['emotionToneScore'] = emotionToneScore\n    \nif languageToneScore:\n    df['languageToneScore'] = languageToneScore\nif highestLanguageTone:\n    df['highestLanguageTone'] = highestLanguageTone\n    \nif highestSocialTone:\n    df['highestSocialTone'] = highestSocialTone    \nif socialToneScore:\n    df['socialToneScore'] = socialToneScore \n    \n#df.head()", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "### <a id='tonearticle'></a> 4.5 Run the Tone Analyzer on the article text\n\nUnlike NLU, the Tone Analyzer cannot iterate through a URL. You first need run an NLU script to pull the article text from the URLs and append the text to the original DataFrame. \n\nRun this NLU script, specifying the MetaData feature, and setting the `return_analyzed_text` parameter to `True`:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 30, 
            "source": "# Extract the free form text response from the DataFrame\n# If you are using this script for a diff CSV, you will have to change this column name\nfree_form_responses = df['Link']\n# define the list of enrichments to apply\n# if you are modifying this script add or remove the enrichments as needed\nf = [features.MetaData()]#'typed-rels'\narticle_text = []\n\n\nfor idx, response in enumerate(free_form_responses):\n    try:\n        enriched_json = json.loads(json.dumps(nlu.analyze(url=response, features=f,return_analyzed_text=True)))\n        #print(enriched_json)\n        article_text.append(enriched_json[\"analyzed_text\"])\n    except:\n    \n        article_text.append(\"\")\n        \n#save to DataFrame\ndf[\"Article Text\"] = article_text\n#df.head()", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "Now run the Tone Analyzer script on the article text. \n\nSet `free_form_responses` to the `Article Text` column:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 31, 
            "source": "# Extract the free form text response from the DataFrame\n# If you are using this script for a different CSV, change this column name\nfree_form_responses = df['Article Text']\n\n#Create a list to store the enriched data\n\nhighestEmotionTone = []\nemotionToneScore = []\n\nlanguageToneScore = []\nhighestLanguageTone = []\n\nsocialToneScore = []\nhighestSocialTone = []\n\n\nfor idx, response in enumerate(free_form_responses):\n    #print(\"Processing record number: \", idx, \" and text: \", response)\n    try:\n        enriched_json = json.loads(json.dumps(tone_analyzer.tone(text=response)))\n        #print(enriched_json)\n        \n        if 'tone_categories' in enriched_json['document_tone']:\n            maxTone = max(enriched_json[\"document_tone\"][\"tone_categories\"][0][\"tones\"], key = itemgetter('score'))['tone_name']      \n            highestEmotionTone.append(maxTone)\n            maxToneScore = max(enriched_json[\"document_tone\"][\"tone_categories\"][0][\"tones\"], key = itemgetter('score'))['score']\n            emotionToneScore.append(maxToneScore)\n            \n            maxLanguageTone = max(enriched_json[\"document_tone\"][\"tone_categories\"][1][\"tones\"], key = itemgetter('score'))['tone_name']      \n            highestLanguageTone.append(maxLanguageTone)\n            maxLanguageScore = max(enriched_json[\"document_tone\"][\"tone_categories\"][1][\"tones\"], key = itemgetter('score'))['score']\n            languageToneScore.append(maxLanguageScore)\n            \n            maxSocial = max(enriched_json[\"document_tone\"][\"tone_categories\"][2][\"tones\"], key = itemgetter('score'))['tone_name']      \n            highestSocialTone.append(maxSocial)\n            maxSocialScore = max(enriched_json[\"document_tone\"][\"tone_categories\"][2][\"tones\"], key = itemgetter('score'))['score']\n            socialToneScore.append(maxSocialScore)\n            \n    except:\n        # catch *all* exceptions\n        e = sys.exc_info()[0]\n        emotionToneScore.append(' ')\n        highestEmotionTone.append(' ')\n        \n        languageToneScore.append(' ')\n        highestLanguageTone.append(' ')\n        \n        socialToneScore.append(' ')\n        highestSocialTone.append(' ')\n        \n        pass\n    \nif highestEmotionTone:\n    df['articlehighestEmotionTone'] = highestEmotionTone    \nif emotionToneScore:\n    df['articleEmotionToneScore'] = emotionToneScore  \nif languageToneScore:\n    df['articlelanguageToneScore'] = languageToneScore\nif highestLanguageTone:\n    df['articlehighestLanguageTone'] = highestLanguageTone   \nif highestSocialTone:\n    df['articlehighestSocialTone'] = highestSocialTone    \nif socialToneScore:\n    df['articlesocialToneScore'] = socialToneScore \n\ndf.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 31, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "                                     Link                        \ufeffPost ID  \\\n1                                     NaN  187446750783_10153215851080784   \n2                   http://ibm.co/1mngjQu  187446750783_10153357233820784   \n3                   http://ibm.co/1IyCTpX  187446750783_10153353697105784   \n4                http://ibm.co/fb_1XVBwbz  187446750783_10153351555645784   \n5  http://ibm.co/1IvPJFx via Fast Company  187446750783_10153348958265784   \n\n                                           Permalink  \\\n1  https://www.facebook.com/ibmwatson/posts/10153...   \n2  https://www.facebook.com/ibmwatson/posts/10153...   \n3  https://www.facebook.com/ibmwatson/posts/10153...   \n4  https://www.facebook.com/ibmwatson/posts/10153...   \n5  https://www.facebook.com/ibmwatson/posts/10153...   \n\n                                                Text   Type  Countries  \\\n1                           IBM Watson's cover photo  Photo        NaN   \n2  What is Watson? IBM Watson is a technology pla...  Photo        NaN   \n3  Did you know that we have been hosting a serie...  Photo        NaN   \n4  Interested in applying social media analytics ...  Photo        NaN   \n5  Using the Personality Insights API from the Wa...  Photo        NaN   \n\n   Languages            Posted Audience Targeting  Lifetime Post Total Reach  \\\n1        NaN   12/31/2015 6:26                                           158   \n2        NaN   12/30/2015 7:00                                          4203   \n3        NaN   12/28/2015 7:05                                          2847   \n4        NaN   12/27/2015 7:00                                          2514   \n5        NaN  12/26/2015 10:20                                          5873   \n\n            ...            highestLanguageTone  highestSocialTone  \\\n1           ...                                                     \n2           ...                                                     \n3           ...                                                     \n4           ...                                                     \n5           ...                                                     \n\n   socialToneScore  Article Text  articlehighestEmotionTone  \\\n1                                                             \n2                                                             \n3                                                             \n4                                                             \n5                                                             \n\n   articleEmotionToneScore  articlelanguageToneScore  \\\n1                                                      \n2                                                      \n3                                                      \n4                                                      \n5                                                      \n\n   articlehighestLanguageTone  articlehighestSocialTone  \\\n1                                                         \n2                                                         \n3                                                         \n4                                                         \n5                                                         \n\n   articlesocialToneScore  \n1                          \n2                          \n3                          \n4                          \n5                          \n\n[5 rows x 93 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Link</th>\n      <th>\ufeffPost ID</th>\n      <th>Permalink</th>\n      <th>Text</th>\n      <th>Type</th>\n      <th>Countries</th>\n      <th>Languages</th>\n      <th>Posted</th>\n      <th>Audience Targeting</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>...</th>\n      <th>highestLanguageTone</th>\n      <th>highestSocialTone</th>\n      <th>socialToneScore</th>\n      <th>Article Text</th>\n      <th>articlehighestEmotionTone</th>\n      <th>articleEmotionToneScore</th>\n      <th>articlelanguageToneScore</th>\n      <th>articlehighestLanguageTone</th>\n      <th>articlehighestSocialTone</th>\n      <th>articlesocialToneScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>187446750783_10153215851080784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>IBM Watson's cover photo</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/31/2015 6:26</td>\n      <td></td>\n      <td>158</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://ibm.co/1mngjQu</td>\n      <td>187446750783_10153357233820784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>What is Watson? IBM Watson is a technology pla...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/30/2015 7:00</td>\n      <td></td>\n      <td>4203</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://ibm.co/1IyCTpX</td>\n      <td>187446750783_10153353697105784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Did you know that we have been hosting a serie...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/28/2015 7:05</td>\n      <td></td>\n      <td>2847</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://ibm.co/fb_1XVBwbz</td>\n      <td>187446750783_10153351555645784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Interested in applying social media analytics ...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/27/2015 7:00</td>\n      <td></td>\n      <td>2514</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>http://ibm.co/1IvPJFx via Fast Company</td>\n      <td>187446750783_10153348958265784</td>\n      <td>https://www.facebook.com/ibmwatson/posts/10153...</td>\n      <td>Using the Personality Insights API from the Wa...</td>\n      <td>Photo</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12/26/2015 10:20</td>\n      <td></td>\n      <td>5873</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 93 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "### <a id='imageclass'></a> 4.6  Classify images with Visual Recognition\n\nRun this Visual Recognition script to classify the images in posts:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 32, 
            "source": "piclinks = df[\"Image\"]\n\npicclass = []\n\nfor pic in enumerate(piclinks):\n    try:\n        enriched_json = json.loads(json.dumps(visual_recognition.classify(images_url=pic), indent=2))\n        #print(enriched_json)\n        classes = enriched_json['images'][0][\"classifiers\"][0][\"classes\"]\n        length = len(classes)\n        tpicclass = []\n        #for each class within one picture\n        for n in range(0,length):\n            #iclass is one class\n            iclass = classes[n]\n            #for confidence level .70\n            if float(iclass[\"score\"]>=.70):\n                tpicclass.append(iclass[\"class\"]) \n            \n        if(len(tpicclass) > 1):\n            tpicclass = \"\".join(reduce(lambda a, b: a + ', ' + b, tpicclass))\n        elif(len(tpicclass) == 0):\n            tpicclass = \"\"\n        else:\n            tpicclass = \"\".join(reduce(lambda a, b: a + ', ' + b, tpicclass))\n\n        picclass.append(tpicclass)\n        \n    except:\n        # catch *all* exceptions\n        e = sys.exc_info()[0]\n        picclass.append(' ')\n        pass\n\ndf[\"PicClass\"] = picclass", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 33, 
            "source": "picclass[:]", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 33, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ',\n ' ']"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Enrichment is now COMPLETE!\n\n## <a id='write'></a> 5. Save the enriched DataFrame to object storage\n\nThe last step for Part 1 is to save the enriched DataFrame to your default DSX object storage that's based on the Swift API. \n\nYou'll define a function that saves the file to the object storage container for your project. You'll save the file to your notebook environment. Then you'll run the function with the variables for your credentials and file name that you defined in step [2.2](#load2). By using variables, you can reuse the function for any other file you want to save in the same project's object storage container. \n\nDefine the `put_file` function:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 28, 
            "source": "def put_file(credentials, localfilename):  \n    \"\"\"This functions returns a StringIO object containing\n    the file content from Bluemix Object Storage V3.\"\"\"\n    f = open(localfilename,'r',encoding=\"utf-8\")\n    my_data = f.read()\n    data_to_send = my_data.encode(\"utf-8\")\n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': credentials['username'],'domain': {'id': credentials['domain_id']},\n            'password': credentials['password']}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    #print(resp1_body)\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', credentials['container'], '/',  localfilename])\n                            print(url2)\n    s_subject_token = resp1.headers['x-subject-token']\n    #print(s_subject_token)\n    #print(credentials['container'])\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.put(url=url2, headers=headers2, data = data_to_send )\n    print(resp2)", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "Save the DataFrame as a CSV file in your Spark environment. Make sure to use the same file name as you defined in step [2.2](#load2).", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 29, 
            "source": "#Replace YOURFILENAME \ndf.to_csv('KL POC Demo',index=False)", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "Run the `put_file` function to save the file in your object storage:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 30, 
            "source": "put_file(credentials_856,\"KL POC Demo\")", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "https://dal.objectstorage.open.softlayer.com/v1/AUTH_71bc420ab71847108e035ad5128ec8ba/SPSSWorkshop2016Q4/KL POC Demo\n<Response [201]>\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "When you leave this notebook and look at your project, you'll see the file in the **Files** pane. You can add the file to your project assets by checking the box next to the file and clicking **Apply**. Then you can use the file in any notebook in the project. ", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "# <a id=\"part2\"></a> Part II - Prepare the data \n\nRight now you have all the data in one DataFrame. To make it easier to visualize the data, however, you'll split up the data by the Watson features of tone, entities, and keywords.\n\n## <a id='p2prepare'></a>1. Sort data by feature\n\nYou'll create a list of metrics and separate DataFrames for tone, entities, and keywords.\n\n### <a id='visualizations'></a>1.1 Create a list of metrics  \n\nEach of the DataFrames for Watson features need metrics.  \n\nCreate a list of metrics to add to each DataFrame:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 31, 
            "source": "#Determine which data points are tied to metrics and put them in a list\nmetrics = [\"Lifetime Post Total Reach\", \"Lifetime Post organic reach\", \"Lifetime Post Paid Reach\", \"Lifetime Post Total Impressions\", \"Lifetime Post Organic Impressions\", \n           \"Lifetime Post Paid Impressions\", \"Lifetime Engaged Users\", \"Lifetime Post Consumers\", \"Lifetime Post Consumptions\", \"Lifetime Negative feedback\", \"Lifetime Negative Feedback from Users\", \n           \"Lifetime Post Impressions by people who have liked your Page\", \"Lifetime Post reach by people who like your Page\", \"Lifetime Post Paid Impressions by people who have liked your Page\", \n           \"Lifetime Paid reach of a post by people who like your Page\", \"Lifetime People who have liked your Page and engaged with your post\", \"Lifetime Talking About This (Post) by action type - comment\", \n           \"Lifetime Talking About This (Post) by action type - like\", \"Lifetime Talking About This (Post) by action type - share\", \"Lifetime Post Stories by action type - comment\", \"Lifetime Post Stories by action type - like\", \n           \"Lifetime Post Stories by action type - share\", \"Lifetime Post consumers by type - link clicks\", \"Lifetime Post consumers by type - other clicks\", \"Lifetime Post consumers by type - photo view\", \"Lifetime Post Consumptions by type - link clicks\", \n           \"Lifetime Post Consumptions by type - other clicks\", \"Lifetime Post Consumptions by type - photo view\", \"Lifetime Negative feedback - hide_all_clicks\", \"Lifetime Negative feedback - hide_clicks\", \n           \"Lifetime Negative Feedback from Users by Type - hide_all_clicks\", \"Lifetime Negative Feedback from Users by Type - hide_clicks\"]\n\n", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "### <a id='tone'></a> 1.2 Create a consolidated tone DataFrame\nYou'll create a DataFrame for the tones of the post text and a DataFrame for the tones of the article text. Then you'll combine them into one DataFrame.\n\nCreate a DataFrame for post tones:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 32, 
            "source": "#Create a list with only Post Tone Values\npost_tones = [\"Text\",\"highestEmotionTone\", \"emotionToneScore\", \"languageToneScore\", \"highestLanguageTone\", \"highestSocialTone\", \"socialToneScore\"]\n\n#Append DataFrame with these metrics\npost_tones.extend(metrics)\n\n#Create a new DataFrame with tones and metrics\ndf_post_tones = df[post_tones]\n\n#Determine which tone values should be numeric and make them numeric. \npost_numeric_values = [\"emotionToneScore\", \"languageToneScore\", \"socialToneScore\"]\nfor i in post_numeric_values:\n    df_post_tones[i] = pd.to_numeric(df_post_tones[i], errors='coerce')\n\n#Make all metrics numeric\nfor i in metrics:\n    df_post_tones[i] = pd.to_numeric(df_post_tones[i], errors='coerce')\n    \n#Drop NA Values in Tone Enrichment Columns\ndf_post_tones.dropna(subset=[\"socialToneScore\"] , inplace = True)\n\n\n#Add in a column to distinguish the type of data that's being enriched \ndf_post_tones[\"Type\"] = \"Post\"\n\ndf_post_tones.info()", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }, 
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 0 entries\nData columns (total 40 columns):\nText                                                                   0 non-null object\nhighestEmotionTone                                                     0 non-null object\nemotionToneScore                                                       0 non-null float64\nlanguageToneScore                                                      0 non-null float64\nhighestLanguageTone                                                    0 non-null object\nhighestSocialTone                                                      0 non-null object\nsocialToneScore                                                        0 non-null float64\nLifetime Post Total Reach                                              0 non-null int64\nLifetime Post organic reach                                            0 non-null int64\nLifetime Post Paid Reach                                               0 non-null int64\nLifetime Post Total Impressions                                        0 non-null int64\nLifetime Post Organic Impressions                                      0 non-null int64\nLifetime Post Paid Impressions                                         0 non-null int64\nLifetime Engaged Users                                                 0 non-null int64\nLifetime Post Consumers                                                0 non-null int64\nLifetime Post Consumptions                                             0 non-null int64\nLifetime Negative feedback                                             0 non-null int64\nLifetime Negative Feedback from Users                                  0 non-null int64\nLifetime Post Impressions by people who have liked your Page           0 non-null int64\nLifetime Post reach by people who like your Page                       0 non-null int64\nLifetime Post Paid Impressions by people who have liked your Page      0 non-null int64\nLifetime Paid reach of a post by people who like your Page             0 non-null int64\nLifetime People who have liked your Page and engaged with your post    0 non-null int64\nLifetime Talking About This (Post) by action type - comment            0 non-null float64\nLifetime Talking About This (Post) by action type - like               0 non-null float64\nLifetime Talking About This (Post) by action type - share              0 non-null float64\nLifetime Post Stories by action type - comment                         0 non-null float64\nLifetime Post Stories by action type - like                            0 non-null float64\nLifetime Post Stories by action type - share                           0 non-null float64\nLifetime Post consumers by type - link clicks                          0 non-null float64\nLifetime Post consumers by type - other clicks                         0 non-null float64\nLifetime Post consumers by type - photo view                           0 non-null float64\nLifetime Post Consumptions by type - link clicks                       0 non-null float64\nLifetime Post Consumptions by type - other clicks                      0 non-null float64\nLifetime Post Consumptions by type - photo view                        0 non-null float64\nLifetime Negative feedback - hide_all_clicks                           0 non-null float64\nLifetime Negative feedback - hide_clicks                               0 non-null float64\nLifetime Negative Feedback from Users by Type - hide_all_clicks        0 non-null float64\nLifetime Negative Feedback from Users by Type - hide_clicks            0 non-null float64\nType                                                                   0 non-null object\ndtypes: float64(19), int64(16), object(5)\nmemory usage: 0.0+ bytes\n"
                }, 
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Create a DataFrame for article tones:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 33, 
            "source": "#Create a list with only Article Tone Values\narticle_tones = [\"Text\", \"articlehighestEmotionTone\", \"articleEmotionToneScore\", \"articlelanguageToneScore\", \"articlehighestLanguageTone\", \"articlehighestSocialTone\", \"articlesocialToneScore\"]\n\n#Append DataFrame with these metrics\narticle_tones.extend(metrics)\n\n#Create a new DataFrame with tones and metrics\ndf_article_tones = df[article_tones]\n\n#Determine which values should be numeric and make them numeric. \nart_numeric_values = [\"articleEmotionToneScore\", \"articlelanguageToneScore\", \"articlesocialToneScore\"]\nfor i in art_numeric_values:\n    df_article_tones[i] = pd.to_numeric(df_article_tones[i], errors='coerce')\n    \n#Make all metrics numeric\nfor i in metrics:\n    df_article_tones[i] = pd.to_numeric(df_article_tones[i], errors='coerce')\n    \n#Drop NA Values in Tone Enrichment Columns\ndf_article_tones.dropna(subset=[\"articlesocialToneScore\"] , inplace = True)\n\n#Add in a column to distinguish the type of data that's being enriched \ndf_article_tones[\"Type\"] = \"Article\"\n\ndf_article_tones.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }, 
                {
                    "execution_count": 33, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Empty DataFrame\nColumns: [Text, articlehighestEmotionTone, articleEmotionToneScore, articlelanguageToneScore, articlehighestLanguageTone, articlehighestSocialTone, articlesocialToneScore, Lifetime Post Total Reach, Lifetime Post organic reach, Lifetime Post Paid Reach, Lifetime Post Total Impressions, Lifetime Post Organic Impressions, Lifetime Post Paid Impressions, Lifetime Engaged Users, Lifetime Post Consumers, Lifetime Post Consumptions, Lifetime Negative feedback, Lifetime Negative Feedback from Users, Lifetime Post Impressions by people who have liked your Page, Lifetime Post reach by people who like your Page, Lifetime Post Paid Impressions by people who have liked your Page, Lifetime Paid reach of a post by people who like your Page, Lifetime People who have liked your Page and engaged with your post, Lifetime Talking About This (Post) by action type - comment, Lifetime Talking About This (Post) by action type - like, Lifetime Talking About This (Post) by action type - share, Lifetime Post Stories by action type - comment, Lifetime Post Stories by action type - like, Lifetime Post Stories by action type - share, Lifetime Post consumers by type - link clicks, Lifetime Post consumers by type - other clicks, Lifetime Post consumers by type - photo view, Lifetime Post Consumptions by type - link clicks, Lifetime Post Consumptions by type - other clicks, Lifetime Post Consumptions by type - photo view, Lifetime Negative feedback - hide_all_clicks, Lifetime Negative feedback - hide_clicks, Lifetime Negative Feedback from Users by Type - hide_all_clicks, Lifetime Negative Feedback from Users by Type - hide_clicks, Type]\nIndex: []\n\n[0 rows x 40 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>articlehighestEmotionTone</th>\n      <th>articleEmotionToneScore</th>\n      <th>articlelanguageToneScore</th>\n      <th>articlehighestLanguageTone</th>\n      <th>articlehighestSocialTone</th>\n      <th>articlesocialToneScore</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>Lifetime Post organic reach</th>\n      <th>Lifetime Post Paid Reach</th>\n      <th>...</th>\n      <th>Lifetime Post consumers by type - other clicks</th>\n      <th>Lifetime Post consumers by type - photo view</th>\n      <th>Lifetime Post Consumptions by type - link clicks</th>\n      <th>Lifetime Post Consumptions by type - other clicks</th>\n      <th>Lifetime Post Consumptions by type - photo view</th>\n      <th>Lifetime Negative feedback - hide_all_clicks</th>\n      <th>Lifetime Negative feedback - hide_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_all_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_clicks</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows \u00d7 40 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Combine the post and article DataFrames to make a consolidated tone DataFrame:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 34, 
            "source": "#first make the Column Headers the same\ndf_post_tones.rename(columns={\"highestEmotionTone\":\"Emotion Tone\", \"emotionToneScore\":\"Emotion Tone Score\", \"languageToneScore\": \"Language Tone Score\", \"highestLanguageTone\": \"Language Tone\", \"highestSocialTone\": \"Social Tone\", \"socialToneScore\":\"Social Tone Score\"\n}, inplace=True)\n\ndf_article_tones.rename(columns={\"articlehighestEmotionTone\":\"Emotion Tone\", \"articleEmotionToneScore\":\"Emotion Tone Score\", \"articlelanguageToneScore\": \"Language Tone Score\", \"articlehighestLanguageTone\": \"Language Tone\", \"articlehighestSocialTone\": \"Social Tone\", \"articlesocialToneScore\":\"Social Tone Score\"\n}, inplace=True)\n\n#Combine into one DataFrame\ndf_tones = pd.concat([df_post_tones, df_article_tones])\n\ndf_tones.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/pandas/core/frame.py:2754: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  **kwargs)\n"
                }, 
                {
                    "execution_count": 34, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Empty DataFrame\nColumns: [Text, Emotion Tone, Emotion Tone Score, Language Tone Score, Language Tone, Social Tone, Social Tone Score, Lifetime Post Total Reach, Lifetime Post organic reach, Lifetime Post Paid Reach, Lifetime Post Total Impressions, Lifetime Post Organic Impressions, Lifetime Post Paid Impressions, Lifetime Engaged Users, Lifetime Post Consumers, Lifetime Post Consumptions, Lifetime Negative feedback, Lifetime Negative Feedback from Users, Lifetime Post Impressions by people who have liked your Page, Lifetime Post reach by people who like your Page, Lifetime Post Paid Impressions by people who have liked your Page, Lifetime Paid reach of a post by people who like your Page, Lifetime People who have liked your Page and engaged with your post, Lifetime Talking About This (Post) by action type - comment, Lifetime Talking About This (Post) by action type - like, Lifetime Talking About This (Post) by action type - share, Lifetime Post Stories by action type - comment, Lifetime Post Stories by action type - like, Lifetime Post Stories by action type - share, Lifetime Post consumers by type - link clicks, Lifetime Post consumers by type - other clicks, Lifetime Post consumers by type - photo view, Lifetime Post Consumptions by type - link clicks, Lifetime Post Consumptions by type - other clicks, Lifetime Post Consumptions by type - photo view, Lifetime Negative feedback - hide_all_clicks, Lifetime Negative feedback - hide_clicks, Lifetime Negative Feedback from Users by Type - hide_all_clicks, Lifetime Negative Feedback from Users by Type - hide_clicks, Type]\nIndex: []\n\n[0 rows x 40 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Emotion Tone</th>\n      <th>Emotion Tone Score</th>\n      <th>Language Tone Score</th>\n      <th>Language Tone</th>\n      <th>Social Tone</th>\n      <th>Social Tone Score</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>Lifetime Post organic reach</th>\n      <th>Lifetime Post Paid Reach</th>\n      <th>...</th>\n      <th>Lifetime Post consumers by type - other clicks</th>\n      <th>Lifetime Post consumers by type - photo view</th>\n      <th>Lifetime Post Consumptions by type - link clicks</th>\n      <th>Lifetime Post Consumptions by type - other clicks</th>\n      <th>Lifetime Post Consumptions by type - photo view</th>\n      <th>Lifetime Negative feedback - hide_all_clicks</th>\n      <th>Lifetime Negative feedback - hide_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_all_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_clicks</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows \u00d7 40 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "### <a id='keyword'></a> 1.3 Create a consolidated keyword DataFrame\nYou'll create DataFrames for the keywords of the article text, the thumbnail text, and the post text. Then you'll combine them into one DataFrame.\n\nCreate a DataFrame for article keywords:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 35, 
            "source": "#Create a list with only Article Keywords\narticle_keywords = [\"Text\", \"MaxLinkKeywords\"]\n\n#Append DataFrame with these metrics\narticle_keywords.extend(metrics)\n\n#Create a new DataFrame with keywords and metrics\ndf_article_keywords = df[article_keywords]\n\n#Make all metrics numeric\nfor i in metrics:\n    df_article_keywords[i] = pd.to_numeric(df_article_keywords[i], errors='coerce')\n  \n#Drop NA Values in Keywords Column\n\ndf_article_keywords['MaxLinkKeywords'].replace(' ', np.nan, inplace=True)\ndf_article_keywords.dropna(subset=['MaxLinkKeywords'], inplace=True)\n\n#Add in a column to distinguish the type of data that's being enriched \ndf_article_keywords[\"Type\"] = \"Article\"\n\ndf_article_keywords.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/pandas/core/generic.py:3443: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self._update_inplace(new_data)\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }, 
                {
                    "execution_count": 35, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Empty DataFrame\nColumns: [Text, MaxLinkKeywords, Lifetime Post Total Reach, Lifetime Post organic reach, Lifetime Post Paid Reach, Lifetime Post Total Impressions, Lifetime Post Organic Impressions, Lifetime Post Paid Impressions, Lifetime Engaged Users, Lifetime Post Consumers, Lifetime Post Consumptions, Lifetime Negative feedback, Lifetime Negative Feedback from Users, Lifetime Post Impressions by people who have liked your Page, Lifetime Post reach by people who like your Page, Lifetime Post Paid Impressions by people who have liked your Page, Lifetime Paid reach of a post by people who like your Page, Lifetime People who have liked your Page and engaged with your post, Lifetime Talking About This (Post) by action type - comment, Lifetime Talking About This (Post) by action type - like, Lifetime Talking About This (Post) by action type - share, Lifetime Post Stories by action type - comment, Lifetime Post Stories by action type - like, Lifetime Post Stories by action type - share, Lifetime Post consumers by type - link clicks, Lifetime Post consumers by type - other clicks, Lifetime Post consumers by type - photo view, Lifetime Post Consumptions by type - link clicks, Lifetime Post Consumptions by type - other clicks, Lifetime Post Consumptions by type - photo view, Lifetime Negative feedback - hide_all_clicks, Lifetime Negative feedback - hide_clicks, Lifetime Negative Feedback from Users by Type - hide_all_clicks, Lifetime Negative Feedback from Users by Type - hide_clicks, Type]\nIndex: []\n\n[0 rows x 35 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>MaxLinkKeywords</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>Lifetime Post organic reach</th>\n      <th>Lifetime Post Paid Reach</th>\n      <th>Lifetime Post Total Impressions</th>\n      <th>Lifetime Post Organic Impressions</th>\n      <th>Lifetime Post Paid Impressions</th>\n      <th>Lifetime Engaged Users</th>\n      <th>Lifetime Post Consumers</th>\n      <th>...</th>\n      <th>Lifetime Post consumers by type - other clicks</th>\n      <th>Lifetime Post consumers by type - photo view</th>\n      <th>Lifetime Post Consumptions by type - link clicks</th>\n      <th>Lifetime Post Consumptions by type - other clicks</th>\n      <th>Lifetime Post Consumptions by type - photo view</th>\n      <th>Lifetime Negative feedback - hide_all_clicks</th>\n      <th>Lifetime Negative feedback - hide_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_all_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_clicks</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows \u00d7 35 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Create a DataFrame for thumbnail keywords:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 36, 
            "source": "#Create a list with only Thumbnail Keywords\nthumbnail_keywords = [\"Text\", \"MaxThumbnailKeywords\"]\n\n#Append DataFrame with these metrics\nthumbnail_keywords.extend(metrics)\n\n#Create a new DataFrame with keywords and metrics\ndf_thumbnail_keywords = df[thumbnail_keywords]\n\n\n#Make all metrics numeric\nfor i in metrics:\n    df_thumbnail_keywords[i] = pd.to_numeric(df_thumbnail_keywords[i], errors='coerce')\n    \n#Drop NA Values in Keywords Column\n\ndf_thumbnail_keywords['MaxThumbnailKeywords'].replace(' ', np.nan, inplace=True)\ndf_thumbnail_keywords.dropna(subset=['MaxThumbnailKeywords'], inplace=True)\n\n#Add in a column to distinguish the type of data that's being enriched \ndf_thumbnail_keywords[\"Type\"] = \"Thumbnails\"\n\ndf_thumbnail_keywords.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/pandas/core/generic.py:3443: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self._update_inplace(new_data)\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }, 
                {
                    "execution_count": 36, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Empty DataFrame\nColumns: [Text, MaxThumbnailKeywords, Lifetime Post Total Reach, Lifetime Post organic reach, Lifetime Post Paid Reach, Lifetime Post Total Impressions, Lifetime Post Organic Impressions, Lifetime Post Paid Impressions, Lifetime Engaged Users, Lifetime Post Consumers, Lifetime Post Consumptions, Lifetime Negative feedback, Lifetime Negative Feedback from Users, Lifetime Post Impressions by people who have liked your Page, Lifetime Post reach by people who like your Page, Lifetime Post Paid Impressions by people who have liked your Page, Lifetime Paid reach of a post by people who like your Page, Lifetime People who have liked your Page and engaged with your post, Lifetime Talking About This (Post) by action type - comment, Lifetime Talking About This (Post) by action type - like, Lifetime Talking About This (Post) by action type - share, Lifetime Post Stories by action type - comment, Lifetime Post Stories by action type - like, Lifetime Post Stories by action type - share, Lifetime Post consumers by type - link clicks, Lifetime Post consumers by type - other clicks, Lifetime Post consumers by type - photo view, Lifetime Post Consumptions by type - link clicks, Lifetime Post Consumptions by type - other clicks, Lifetime Post Consumptions by type - photo view, Lifetime Negative feedback - hide_all_clicks, Lifetime Negative feedback - hide_clicks, Lifetime Negative Feedback from Users by Type - hide_all_clicks, Lifetime Negative Feedback from Users by Type - hide_clicks, Type]\nIndex: []\n\n[0 rows x 35 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>MaxThumbnailKeywords</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>Lifetime Post organic reach</th>\n      <th>Lifetime Post Paid Reach</th>\n      <th>Lifetime Post Total Impressions</th>\n      <th>Lifetime Post Organic Impressions</th>\n      <th>Lifetime Post Paid Impressions</th>\n      <th>Lifetime Engaged Users</th>\n      <th>Lifetime Post Consumers</th>\n      <th>...</th>\n      <th>Lifetime Post consumers by type - other clicks</th>\n      <th>Lifetime Post consumers by type - photo view</th>\n      <th>Lifetime Post Consumptions by type - link clicks</th>\n      <th>Lifetime Post Consumptions by type - other clicks</th>\n      <th>Lifetime Post Consumptions by type - photo view</th>\n      <th>Lifetime Negative feedback - hide_all_clicks</th>\n      <th>Lifetime Negative feedback - hide_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_all_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_clicks</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows \u00d7 35 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Create a DataFrame for post keywords:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 37, 
            "source": "#Create a list with only Thumbnail Keywords\npost_keywords = [\"Text\", \"MaxTextKeywords\"]\n\n#Append DataFrame with these metrics\npost_keywords.extend(metrics)\n\n#Create a new DataFrame with keywords and metrics\ndf_post_keywords = df[post_keywords]\n\n#Make all metrics numeric\nfor i in metrics:\n    df_post_keywords[i] = pd.to_numeric(df_post_keywords[i], errors='coerce')\n    \n#Drop NA Values in Keywords Column\n\ndf_post_keywords['MaxTextKeywords'].replace(' ', np.nan, inplace=True)\ndf_post_keywords.dropna(subset=['MaxTextKeywords'], inplace=True)\n\n#Add in a column to distinguish the type of data that's being enriched \ndf_post_keywords[\"Type\"] = \"Posts\"\n\ndf_post_keywords.info()", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }, 
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 0 entries\nData columns (total 35 columns):\nText                                                                   0 non-null object\nMaxTextKeywords                                                        0 non-null float64\nLifetime Post Total Reach                                              0 non-null int64\nLifetime Post organic reach                                            0 non-null int64\nLifetime Post Paid Reach                                               0 non-null int64\nLifetime Post Total Impressions                                        0 non-null int64\nLifetime Post Organic Impressions                                      0 non-null int64\nLifetime Post Paid Impressions                                         0 non-null int64\nLifetime Engaged Users                                                 0 non-null int64\nLifetime Post Consumers                                                0 non-null int64\nLifetime Post Consumptions                                             0 non-null int64\nLifetime Negative feedback                                             0 non-null int64\nLifetime Negative Feedback from Users                                  0 non-null int64\nLifetime Post Impressions by people who have liked your Page           0 non-null int64\nLifetime Post reach by people who like your Page                       0 non-null int64\nLifetime Post Paid Impressions by people who have liked your Page      0 non-null int64\nLifetime Paid reach of a post by people who like your Page             0 non-null int64\nLifetime People who have liked your Page and engaged with your post    0 non-null int64\nLifetime Talking About This (Post) by action type - comment            0 non-null float64\nLifetime Talking About This (Post) by action type - like               0 non-null float64\nLifetime Talking About This (Post) by action type - share              0 non-null float64\nLifetime Post Stories by action type - comment                         0 non-null float64\nLifetime Post Stories by action type - like                            0 non-null float64\nLifetime Post Stories by action type - share                           0 non-null float64\nLifetime Post consumers by type - link clicks                          0 non-null float64\nLifetime Post consumers by type - other clicks                         0 non-null float64\nLifetime Post consumers by type - photo view                           0 non-null float64\nLifetime Post Consumptions by type - link clicks                       0 non-null float64\nLifetime Post Consumptions by type - other clicks                      0 non-null float64\nLifetime Post Consumptions by type - photo view                        0 non-null float64\nLifetime Negative feedback - hide_all_clicks                           0 non-null float64\nLifetime Negative feedback - hide_clicks                               0 non-null float64\nLifetime Negative Feedback from Users by Type - hide_all_clicks        0 non-null float64\nLifetime Negative Feedback from Users by Type - hide_clicks            0 non-null float64\nType                                                                   0 non-null object\ndtypes: float64(17), int64(16), object(2)\nmemory usage: 0.0+ bytes\n"
                }, 
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/pandas/core/generic.py:3443: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self._update_inplace(new_data)\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Combine the article, thumbnail, and post DataFrames to make a consolidated keywords DataFrame:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 38, 
            "source": "#first make the Column Headers the same\ndf_post_keywords.rename(columns={\"MaxTextKeywords\": \"Keywords\"}, inplace=True)\n\ndf_thumbnail_keywords.rename(columns={\"MaxThumbnailKeywords\":\"Keywords\"}, inplace=True)\n\ndf_article_keywords.rename(columns={\"MaxLinkKeywords\":\"Keywords\"}, inplace=True)\n\n#Combine into one DataFrame\ndf_keywords = pd.concat([df_post_keywords, df_thumbnail_keywords, df_article_keywords])\n\ndf_keywords = df_keywords[df_keywords[\"Lifetime Post Consumptions\"]>700]\n\ndf_keywords.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/pandas/core/frame.py:2754: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  **kwargs)\n"
                }, 
                {
                    "execution_count": 38, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Empty DataFrame\nColumns: [Text, Keywords, Lifetime Post Total Reach, Lifetime Post organic reach, Lifetime Post Paid Reach, Lifetime Post Total Impressions, Lifetime Post Organic Impressions, Lifetime Post Paid Impressions, Lifetime Engaged Users, Lifetime Post Consumers, Lifetime Post Consumptions, Lifetime Negative feedback, Lifetime Negative Feedback from Users, Lifetime Post Impressions by people who have liked your Page, Lifetime Post reach by people who like your Page, Lifetime Post Paid Impressions by people who have liked your Page, Lifetime Paid reach of a post by people who like your Page, Lifetime People who have liked your Page and engaged with your post, Lifetime Talking About This (Post) by action type - comment, Lifetime Talking About This (Post) by action type - like, Lifetime Talking About This (Post) by action type - share, Lifetime Post Stories by action type - comment, Lifetime Post Stories by action type - like, Lifetime Post Stories by action type - share, Lifetime Post consumers by type - link clicks, Lifetime Post consumers by type - other clicks, Lifetime Post consumers by type - photo view, Lifetime Post Consumptions by type - link clicks, Lifetime Post Consumptions by type - other clicks, Lifetime Post Consumptions by type - photo view, Lifetime Negative feedback - hide_all_clicks, Lifetime Negative feedback - hide_clicks, Lifetime Negative Feedback from Users by Type - hide_all_clicks, Lifetime Negative Feedback from Users by Type - hide_clicks, Type]\nIndex: []\n\n[0 rows x 35 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Keywords</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>Lifetime Post organic reach</th>\n      <th>Lifetime Post Paid Reach</th>\n      <th>Lifetime Post Total Impressions</th>\n      <th>Lifetime Post Organic Impressions</th>\n      <th>Lifetime Post Paid Impressions</th>\n      <th>Lifetime Engaged Users</th>\n      <th>Lifetime Post Consumers</th>\n      <th>...</th>\n      <th>Lifetime Post consumers by type - other clicks</th>\n      <th>Lifetime Post consumers by type - photo view</th>\n      <th>Lifetime Post Consumptions by type - link clicks</th>\n      <th>Lifetime Post Consumptions by type - other clicks</th>\n      <th>Lifetime Post Consumptions by type - photo view</th>\n      <th>Lifetime Negative feedback - hide_all_clicks</th>\n      <th>Lifetime Negative feedback - hide_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_all_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_clicks</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows \u00d7 35 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "### <a id='entity'></a> 1.4 Create a consolidated entity DataFrame\nYou'll create DataFrames for the entities of the article text, the thumbnail text, and the post text. Then you'll combine them into one DataFrame.\n\nCreate a DataFrame for article entities:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 39, 
            "source": "#Create a list with only Article Entities\narticle_entities = [\"Text\", \"MaxLinkEntity\"]\n\n#Append DataFrame with these metrics\narticle_entities.extend(metrics)\n\n#Create a new DataFrame with keywords and metrics\ndf_article_entities = df[article_entities]\n    \n#Make all metrics numeric\nfor i in metrics:\n    df_article_entities[i] = pd.to_numeric(df_article_entities[i], errors='coerce')\n    \n#Drop NA Values in Keywords Column\n\ndf_article_entities['MaxLinkEntity'] = df[\"MaxLinkEntity\"].replace(r'\\s+', np.nan, regex=True)\ndf_article_entities.dropna(subset=['MaxLinkEntity'], inplace=True)\n\n#Add in a column to distinguish the type of data that's being enriched \ndf_article_entities[\"Type\"] = \"Article\"\n\ndf_article_entities.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }, 
                {
                    "execution_count": 39, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Empty DataFrame\nColumns: [Text, MaxLinkEntity, Lifetime Post Total Reach, Lifetime Post organic reach, Lifetime Post Paid Reach, Lifetime Post Total Impressions, Lifetime Post Organic Impressions, Lifetime Post Paid Impressions, Lifetime Engaged Users, Lifetime Post Consumers, Lifetime Post Consumptions, Lifetime Negative feedback, Lifetime Negative Feedback from Users, Lifetime Post Impressions by people who have liked your Page, Lifetime Post reach by people who like your Page, Lifetime Post Paid Impressions by people who have liked your Page, Lifetime Paid reach of a post by people who like your Page, Lifetime People who have liked your Page and engaged with your post, Lifetime Talking About This (Post) by action type - comment, Lifetime Talking About This (Post) by action type - like, Lifetime Talking About This (Post) by action type - share, Lifetime Post Stories by action type - comment, Lifetime Post Stories by action type - like, Lifetime Post Stories by action type - share, Lifetime Post consumers by type - link clicks, Lifetime Post consumers by type - other clicks, Lifetime Post consumers by type - photo view, Lifetime Post Consumptions by type - link clicks, Lifetime Post Consumptions by type - other clicks, Lifetime Post Consumptions by type - photo view, Lifetime Negative feedback - hide_all_clicks, Lifetime Negative feedback - hide_clicks, Lifetime Negative Feedback from Users by Type - hide_all_clicks, Lifetime Negative Feedback from Users by Type - hide_clicks, Type]\nIndex: []\n\n[0 rows x 35 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>MaxLinkEntity</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>Lifetime Post organic reach</th>\n      <th>Lifetime Post Paid Reach</th>\n      <th>Lifetime Post Total Impressions</th>\n      <th>Lifetime Post Organic Impressions</th>\n      <th>Lifetime Post Paid Impressions</th>\n      <th>Lifetime Engaged Users</th>\n      <th>Lifetime Post Consumers</th>\n      <th>...</th>\n      <th>Lifetime Post consumers by type - other clicks</th>\n      <th>Lifetime Post consumers by type - photo view</th>\n      <th>Lifetime Post Consumptions by type - link clicks</th>\n      <th>Lifetime Post Consumptions by type - other clicks</th>\n      <th>Lifetime Post Consumptions by type - photo view</th>\n      <th>Lifetime Negative feedback - hide_all_clicks</th>\n      <th>Lifetime Negative feedback - hide_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_all_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_clicks</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows \u00d7 35 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Create a DataFrame for thumbnail entities:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 40, 
            "source": "#Create a list with only Thumbnail Entities\nthumbnail_entities = [\"Text\", \"MaxThumbnailEntity\"]\n\n#Append DataFrame with these metrics\nthumbnail_entities.extend(metrics)\n\n#Create a new DataFrame with keywords and metrics\ndf_thumbnail_entities = df[thumbnail_entities]\n\n#Make all metrics numeric\nfor i in metrics:\n    df_thumbnail_entities[i] = pd.to_numeric(df_thumbnail_entities[i], errors='coerce')\n    \n#Drop NA Values in Keywords Column\n\ndf_thumbnail_entities['MaxThumbnailEntity'] = df_thumbnail_entities['MaxThumbnailEntity'].replace(r'\\s+', np.nan, regex=True)\ndf_thumbnail_entities.dropna(subset=['MaxThumbnailEntity'], inplace=True)\n\n#Add in a column to distinguish the type of data that's being enriched \ndf_thumbnail_entities[\"Type\"] = \"Thumbnails\"\n\ndf_thumbnail_entities.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }, 
                {
                    "execution_count": 40, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Empty DataFrame\nColumns: [Text, MaxThumbnailEntity, Lifetime Post Total Reach, Lifetime Post organic reach, Lifetime Post Paid Reach, Lifetime Post Total Impressions, Lifetime Post Organic Impressions, Lifetime Post Paid Impressions, Lifetime Engaged Users, Lifetime Post Consumers, Lifetime Post Consumptions, Lifetime Negative feedback, Lifetime Negative Feedback from Users, Lifetime Post Impressions by people who have liked your Page, Lifetime Post reach by people who like your Page, Lifetime Post Paid Impressions by people who have liked your Page, Lifetime Paid reach of a post by people who like your Page, Lifetime People who have liked your Page and engaged with your post, Lifetime Talking About This (Post) by action type - comment, Lifetime Talking About This (Post) by action type - like, Lifetime Talking About This (Post) by action type - share, Lifetime Post Stories by action type - comment, Lifetime Post Stories by action type - like, Lifetime Post Stories by action type - share, Lifetime Post consumers by type - link clicks, Lifetime Post consumers by type - other clicks, Lifetime Post consumers by type - photo view, Lifetime Post Consumptions by type - link clicks, Lifetime Post Consumptions by type - other clicks, Lifetime Post Consumptions by type - photo view, Lifetime Negative feedback - hide_all_clicks, Lifetime Negative feedback - hide_clicks, Lifetime Negative Feedback from Users by Type - hide_all_clicks, Lifetime Negative Feedback from Users by Type - hide_clicks, Type]\nIndex: []\n\n[0 rows x 35 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>MaxThumbnailEntity</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>Lifetime Post organic reach</th>\n      <th>Lifetime Post Paid Reach</th>\n      <th>Lifetime Post Total Impressions</th>\n      <th>Lifetime Post Organic Impressions</th>\n      <th>Lifetime Post Paid Impressions</th>\n      <th>Lifetime Engaged Users</th>\n      <th>Lifetime Post Consumers</th>\n      <th>...</th>\n      <th>Lifetime Post consumers by type - other clicks</th>\n      <th>Lifetime Post consumers by type - photo view</th>\n      <th>Lifetime Post Consumptions by type - link clicks</th>\n      <th>Lifetime Post Consumptions by type - other clicks</th>\n      <th>Lifetime Post Consumptions by type - photo view</th>\n      <th>Lifetime Negative feedback - hide_all_clicks</th>\n      <th>Lifetime Negative feedback - hide_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_all_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_clicks</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows \u00d7 35 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Create a DataFrame for post entities:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 41, 
            "source": "#Create a list with only Post Entities\npost_entities = [\"Text\", \"MaxTextEntity\"]\n\n#Append DataFrame with these metrics\npost_entities.extend(metrics)\n\n#Create a new DataFrame with keywords and metrics\ndf_post_entities = df[post_entities]\n\n#Make all metrics numeric\nfor i in metrics:\n    df_post_entities[i] = pd.to_numeric(df_post_entities[i], errors='coerce')\n    \n#Drop NA Values in Keywords Column\n\ndf_post_entities['MaxTextEntity'] = df_post_entities['MaxTextEntity'].replace(r'\\s+', np.nan, regex=True)\ndf_post_entities.dropna(subset=['MaxTextEntity'], inplace=True)\n\n#Add in a column to distinguish the type of data that's being enriched \ndf_post_entities[\"Type\"] = \"Posts\"\n\ndf_post_entities.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }, 
                {
                    "execution_count": 41, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Empty DataFrame\nColumns: [Text, MaxTextEntity, Lifetime Post Total Reach, Lifetime Post organic reach, Lifetime Post Paid Reach, Lifetime Post Total Impressions, Lifetime Post Organic Impressions, Lifetime Post Paid Impressions, Lifetime Engaged Users, Lifetime Post Consumers, Lifetime Post Consumptions, Lifetime Negative feedback, Lifetime Negative Feedback from Users, Lifetime Post Impressions by people who have liked your Page, Lifetime Post reach by people who like your Page, Lifetime Post Paid Impressions by people who have liked your Page, Lifetime Paid reach of a post by people who like your Page, Lifetime People who have liked your Page and engaged with your post, Lifetime Talking About This (Post) by action type - comment, Lifetime Talking About This (Post) by action type - like, Lifetime Talking About This (Post) by action type - share, Lifetime Post Stories by action type - comment, Lifetime Post Stories by action type - like, Lifetime Post Stories by action type - share, Lifetime Post consumers by type - link clicks, Lifetime Post consumers by type - other clicks, Lifetime Post consumers by type - photo view, Lifetime Post Consumptions by type - link clicks, Lifetime Post Consumptions by type - other clicks, Lifetime Post Consumptions by type - photo view, Lifetime Negative feedback - hide_all_clicks, Lifetime Negative feedback - hide_clicks, Lifetime Negative Feedback from Users by Type - hide_all_clicks, Lifetime Negative Feedback from Users by Type - hide_clicks, Type]\nIndex: []\n\n[0 rows x 35 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>MaxTextEntity</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>Lifetime Post organic reach</th>\n      <th>Lifetime Post Paid Reach</th>\n      <th>Lifetime Post Total Impressions</th>\n      <th>Lifetime Post Organic Impressions</th>\n      <th>Lifetime Post Paid Impressions</th>\n      <th>Lifetime Engaged Users</th>\n      <th>Lifetime Post Consumers</th>\n      <th>...</th>\n      <th>Lifetime Post consumers by type - other clicks</th>\n      <th>Lifetime Post consumers by type - photo view</th>\n      <th>Lifetime Post Consumptions by type - link clicks</th>\n      <th>Lifetime Post Consumptions by type - other clicks</th>\n      <th>Lifetime Post Consumptions by type - photo view</th>\n      <th>Lifetime Negative feedback - hide_all_clicks</th>\n      <th>Lifetime Negative feedback - hide_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_all_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_clicks</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows \u00d7 35 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Combine the post, thumbnail, and article DataFrames to Make a consolidated entities DataFrame:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 42, 
            "source": "#first make the Column Headers the same\ndf_post_entities.rename(columns={\"MaxTextEntity\": \"Entities\"}, inplace=True)\n\ndf_thumbnail_entities.rename(columns={\"MaxThumbnailEntity\":\"Entities\"}, inplace=True)\n\ndf_article_entities.rename(columns={\"MaxLinkEntity\":\"Entities\"}, inplace=True)\n\n#Combine into one DataFrame\ndf_entities = pd.concat([df_post_entities, df_thumbnail_entities, df_article_entities])\n\ndf_entities[\"Entities\"] = df_entities[\"Entities\"].replace('', np.nan)\ndf_entities.dropna(subset=[\"Entities\"], inplace=True)\n\ndf_entities.head()", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/conda3_runtime.v21/4.1.1/lib/python3.5/site-packages/pandas/core/frame.py:2754: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  **kwargs)\n"
                }, 
                {
                    "execution_count": 42, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Empty DataFrame\nColumns: [Text, Entities, Lifetime Post Total Reach, Lifetime Post organic reach, Lifetime Post Paid Reach, Lifetime Post Total Impressions, Lifetime Post Organic Impressions, Lifetime Post Paid Impressions, Lifetime Engaged Users, Lifetime Post Consumers, Lifetime Post Consumptions, Lifetime Negative feedback, Lifetime Negative Feedback from Users, Lifetime Post Impressions by people who have liked your Page, Lifetime Post reach by people who like your Page, Lifetime Post Paid Impressions by people who have liked your Page, Lifetime Paid reach of a post by people who like your Page, Lifetime People who have liked your Page and engaged with your post, Lifetime Talking About This (Post) by action type - comment, Lifetime Talking About This (Post) by action type - like, Lifetime Talking About This (Post) by action type - share, Lifetime Post Stories by action type - comment, Lifetime Post Stories by action type - like, Lifetime Post Stories by action type - share, Lifetime Post consumers by type - link clicks, Lifetime Post consumers by type - other clicks, Lifetime Post consumers by type - photo view, Lifetime Post Consumptions by type - link clicks, Lifetime Post Consumptions by type - other clicks, Lifetime Post Consumptions by type - photo view, Lifetime Negative feedback - hide_all_clicks, Lifetime Negative feedback - hide_clicks, Lifetime Negative Feedback from Users by Type - hide_all_clicks, Lifetime Negative Feedback from Users by Type - hide_clicks, Type]\nIndex: []\n\n[0 rows x 35 columns]", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Entities</th>\n      <th>Lifetime Post Total Reach</th>\n      <th>Lifetime Post organic reach</th>\n      <th>Lifetime Post Paid Reach</th>\n      <th>Lifetime Post Total Impressions</th>\n      <th>Lifetime Post Organic Impressions</th>\n      <th>Lifetime Post Paid Impressions</th>\n      <th>Lifetime Engaged Users</th>\n      <th>Lifetime Post Consumers</th>\n      <th>...</th>\n      <th>Lifetime Post consumers by type - other clicks</th>\n      <th>Lifetime Post consumers by type - photo view</th>\n      <th>Lifetime Post Consumptions by type - link clicks</th>\n      <th>Lifetime Post Consumptions by type - other clicks</th>\n      <th>Lifetime Post Consumptions by type - photo view</th>\n      <th>Lifetime Negative feedback - hide_all_clicks</th>\n      <th>Lifetime Negative feedback - hide_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_all_clicks</th>\n      <th>Lifetime Negative Feedback from Users by Type - hide_clicks</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows \u00d7 35 columns</p>\n</div>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "# <a id=\"part3\"></a> Part III\n\nNow you're ready to visualize the data! The graphs that you'll create in this section are just examples of the analysis that you can do on the data. \n\n## <a id='2setup'></a> 1. Define variables\n\nDefine variables for the new DataFrames:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 43, 
            "source": "entities = df_entities\ntones = df_tones\nkeywords = df_keywords", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "## <a id='viz'></a> 2. Visualize the data with PixieDust\n\nPixieDust lets you visualize your data in just a few clicks using the <a href=\"https://ibm-cds-labs.github.io/pixiedust/displayapi.html\" target=\"_blank\" rel=\"noopener noreferrer\">display() API</a>. You create graphs with a one-word command and then explore them with an integrated UI instead of code. The `display()` command generates an interactive widget that lets you choose options to explore the data in a myriad of ways.\n\n### <a id='viz1'></a>2.1 View post consumption by tone\nRun the `display()` command and then configure the graph to show the relationship between \u2018Lifetime Post Consumption\u2019 and Emotion Tone for articles and posts:\n\n1. Run the next cell. The PixieDust interactive widget appears.  \n1. Click the chart button and choose **Bar Chart**. The chart options tool appears.\n1. In the chart options tool, drag `Lifetime Post Consumption` into the **Values** box. \n1. Move `Emotion Tone` into the **Keys** box. \n1. Set the Aggregation to **Avg** and click **OK**. The bar chart appears.\n1. From the **Cluster By** list, choose `Type`. Now the chart shows separate bars for articles and posts.\n\nIf you want to make further changes, click **Options** to return to the chart options tool.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 44, 
            "source": "display(tones)", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "rowCount": "500", 
                        "keyFields": "Emotion Tone,Language Tone", 
                        "rendererId": "matplotlib", 
                        "valueFields": "Lifetime Post Consumptions,Lifetime Negative feedback - hide_all_clicks", 
                        "orientation": "horizontal", 
                        "clusterby": "Social Tone", 
                        "aggregation": "SUM", 
                        "handlerId": "barChart"
                    }
                }
            }, 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>", 
                        "text/html": "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>\n        <div class=\"pd_save is-viewer-good\" style=\"padding-right:10px;text-align: center;line-height:initial !important;font-size: xx-large;font-weight: 500;color: coral;\">\n            \n        </div>\n    \n        <div id=\"chartFigure5a50bc6c\" class=\"pd_save\" style=\"overflow-x:auto\">\n            \n                <div style=\"min-height: 50px;\">\n                    <div style=\"color: red;position: absolute;bottom: 0;left: 0;\">Empty 'DataFrame': no numeric data to plot</div>\n                </div>\n            \n        </div>\n    "
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Now use a pie chart to identify how post consumption was broken up by language tone: \n\n1. Run the next cell.\n1. Click the chart button and choose **Pie Chart**. \n1. In the chart options tool, drag `Lifetime Post Consumption` into the **Values** box and drag `Language Tone` into the **Keys** box. \n1. Set the Aggregation to **Avg** and click **OK**. ", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 45, 
            "source": "display(tones)", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "mpld3": "false", 
                        "keyFields": "Language Tone", 
                        "aggregation": "AVG", 
                        "valueFields": "Lifetime Post Consumptions", 
                        "rowCount": "500", 
                        "handlerId": "pieChart"
                    }
                }
            }, 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>", 
                        "text/html": "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>\n        <div class=\"pd_save is-viewer-good\" style=\"padding-right:10px;text-align: center;line-height:initial !important;font-size: xx-large;font-weight: 500;color: coral;\">\n            \n        </div>\n    \n        <div id=\"chartFigure7b956cb6\" class=\"pd_save\" style=\"overflow-x:auto\">\n            \n                <div style=\"min-height: 50px;\">\n                    <div style=\"color: red;position: absolute;bottom: 0;left: 0;\">Empty 'DataFrame': no numeric data to plot</div>\n                </div>\n            \n        </div>\n    "
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "### <a id='viz2'></a>2.2 View post consumption by entity\nNow look at how mean post consumption differs by entity:\n\n1. Create a bar chart with a value of `Lifetime Post Consumption` and a key of `Entities`.\n1. Cluster the results by `Type`.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 46, 
            "source": "display(entities)", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "clusterby": "Type", 
                        "rowCount": "500", 
                        "keyFields": "Entities", 
                        "rendererId": "bokeh", 
                        "aggregation": "SUM", 
                        "valueFields": "Lifetime Post Consumptions", 
                        "handlerId": "pieChart"
                    }
                }, 
                "scrolled": true
            }, 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>", 
                        "text/html": "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>\n        <div class=\"pd_save is-viewer-good\" style=\"padding-right:10px;text-align: center;line-height:initial !important;font-size: xx-large;font-weight: 500;color: coral;\">\n            \n        </div>\n    \n        <div id=\"chartFiguref90e60dd\" class=\"pd_save\" style=\"overflow-x:auto\">\n            \n                <div style=\"min-height: 50px;\">\n                    <div style=\"color: red;position: absolute;bottom: 0;left: 0;\">Empty 'DataFrame': no numeric data to plot</div>\n                </div>\n            \n        </div>\n    "
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "You can see that **Person** has the highest post consumption for articles, while **Company** has the highest for posts.\n\n### <a id='viz3'></a>2.3 View post consumption by keyword\nFinally, look at how post consumption is associated with certain keywords:\n\n1. Create a bar chart with a value of `Lifetime Post Consumption` and a key of `Keywords`.\n1. Cluster the results by `Type`.\n1. Change the orientation to `horizontal`.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 47, 
            "source": "display(keywords)", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "rowCount": "500", 
                        "keyFields": "Keywords", 
                        "rendererId": "matplotlib", 
                        "valueFields": "Lifetime Post Consumptions", 
                        "orientation": "horizontal", 
                        "clusterby": "Type", 
                        "aggregation": "SUM", 
                        "handlerId": "pieChart"
                    }
                }
            }, 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>", 
                        "text/html": "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>\n        <div class=\"pd_save is-viewer-good\" style=\"padding-right:10px;text-align: center;line-height:initial !important;font-size: xx-large;font-weight: 500;color: coral;\">\n            \n        </div>\n    \n        <div id=\"chartFigurec37152af\" class=\"pd_save\" style=\"overflow-x:auto\">\n            \n                <div style=\"min-height: 50px;\">\n                    <div style=\"color: red;position: absolute;bottom: 0;left: 0;\">Empty 'DataFrame': no numeric data to plot</div>\n                </div>\n            \n        </div>\n    "
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Now try creating your own graphs with PixieDust!\n\n## <a id='summary'></a>Summary \n\nYou learned how to enrich data with three Watson services and how to visualize data with PixieDust.\n\nYou have these reusable resources for further exploration:\n\n - A function for saving a DataFrame to your project object storage when you're using Python 3.5.\n - A data file with enriched data that you can analyze in another notebook.\n - Enrichment scripts for each Watson service that you can easily adapt for your own uses.\n\nLearn more about PixieDust:\n - [PixieDust Documentation](https://ibm-cds-labs.github.io/pixiedust/index.html)\n - [PixieDust GitHub Repo](https://github.com/ibm-cds-labs/pixiedust)\n - [Welcome to PixieDust sample notebook](https://apsportal.ibm.com/exchange/public/entry/view/5b000ed5abda694232eb5be84c3dd7c1)", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "### Authors\nTyler Andersen and Anna Quincy are on the IBM Watson Accelerator\u2019s Team. They specialize in combining the power of Watson Services with the Watson Data Platform.\n\n<hr>\nCopyright &copy; IBM Corp. 2017. This notebook and its source code are released under the terms of the MIT License.", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": null, 
            "source": "", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code"
        }
    ]
}